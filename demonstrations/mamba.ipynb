{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c39736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from stelaro.data import format, ncbi\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "DATA_DIRECTORY = \"../data/\"\n",
    "SUMMARY_DIRECTORY = DATA_DIRECTORY + \"ncbi_genome_summaries/\"\n",
    "NCBI_TAXONOMY_DIRECTORY = DATA_DIRECTORY + \"ncbi_taxonomy/\"\n",
    "BERTAX_DIRECTORY = DATA_DIRECTORY + \"bertax/final/\"\n",
    "BERTAX_DATASET_DIRECTORY = BERTAX_DIRECTORY + \"final_model_data_seperate_fasta_per_superkingdom/data/fass2/projects/fk_read_classification/dna_sequences/fragments/genomic_fragments_80_big/\"\n",
    "BERTAX_DOMAINS = (\n",
    "    \"Archaea_db.fa\",\n",
    "    \"Bacteria_db.fa\",\n",
    "    \"Eukaryota_db.fa\",\n",
    "    \"Viruses_db.fa\",\n",
    ")\n",
    "BERTAX_STATISTIC_DIRECTORY = BERTAX_DIRECTORY + \"statistics/\"\n",
    "PROCESSED_PRETRAINING_DATA = DATA_DIRECTORY + \"bertax/pretraining/processed/\"\n",
    "SEQUENCE_LENGTH = 1500\n",
    "N_MINIMUM_READS_PER_TAXON = 10_000\n",
    "\n",
    "\n",
    "def mkdir(path: str) -> None:\n",
    "    \"\"\"Create a directory if it does not exist.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "mkdir(BERTAX_STATISTIC_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a05230c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTAX_TRAIN = BERTAX_DIRECTORY + \"train/\"\n",
    "BERTAX_VALIDATION = BERTAX_DIRECTORY + \"validation/\"\n",
    "BERTAX_TEST = BERTAX_DIRECTORY + \"test/\"\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torch import nn, exp\n",
    "\n",
    "from stelaro.data import format\n",
    "from stelaro import models\n",
    "\n",
    "LENGTH = 1500\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "train_data = DataLoader(\n",
    "    models.SyntheticTetramerDataset(BERTAX_TRAIN),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "validation_data = DataLoader(\n",
    "    models.SyntheticTetramerDataset(BERTAX_VALIDATION),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_data = DataLoader(\n",
    "    models.SyntheticTetramerDataset(BERTAX_TEST),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "with open(BERTAX_DIRECTORY + \"statistics/map.json\", \"r\") as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "\n",
    "def benchmark(\n",
    "        classifier: models.BaseClassifier,\n",
    "        name: str,\n",
    "        max_epochs: int = 20,\n",
    "        loss_fn = nn.CrossEntropyLoss(),\n",
    "        evaluation_interval=5000,\n",
    "        learning_rate: float = 0.001\n",
    "    ):\n",
    "    parameters = classifier.get_parameters()\n",
    "    if parameters:\n",
    "        optimizer = Adam(classifier.get_parameters(), lr=0.001)\n",
    "        total_params = sum(param.numel() for param in parameters)\n",
    "        print(f\"Number of parameters: {total_params:_}\")\n",
    "    else:\n",
    "        optimizer = None\n",
    "    a = time()\n",
    "    losses, f1, validation_losses = classifier.train(\n",
    "        train_data,\n",
    "        validation_data,\n",
    "        optimizer,\n",
    "        max_n_epochs=max_epochs,\n",
    "        patience=3,\n",
    "        loss_function=loss_fn,\n",
    "        loss_function_type=\"supervised\",\n",
    "        evaluation_interval=evaluation_interval\n",
    "    )\n",
    "    b = time()\n",
    "    print(f\"Training took {(b - a):.3f} s.\")\n",
    "    if losses:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        x = list(range(len(losses)))\n",
    "        ax[0].plot(x, losses, label=\"Training\")\n",
    "        ax[0].plot(x, validation_losses, label=\"Validation\")\n",
    "        ax[0].set(xlabel='Epochs', ylabel='Loss')\n",
    "        ax[0].set_title(\"Normalized Loss Against Epochs\")\n",
    "        ax[0].legend()\n",
    "        ax[1].set(xlabel='Epochs', ylabel=\"f1\")\n",
    "        ax[1].set_title(\"F1 Score\")\n",
    "        r = 0\n",
    "        for f in f1:\n",
    "            ax[1].plot(x, f, label=f'Rank {r}')\n",
    "            r += 1\n",
    "        ax[1].legend()\n",
    "        fig.suptitle(f\"Classification Training for {name}\")\n",
    "        plt.show()\n",
    "    result = models.evaluate(classifier, test_data, \"cuda\", mapping)\n",
    "    rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "    print(f\"F1: {rounded_result}\")\n",
    "    result = models.evaluate_precision(classifier, test_data, \"cuda\", mapping)\n",
    "    rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "    print(f\"Precision: {rounded_result}\")\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2394d",
   "metadata": {},
   "source": [
    "# One-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 388_785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2003/9196 [04:03<6:20:14,  3.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.57526, 0.22857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [08:44<5:56:33,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.65106, 0.35171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [13:25<5:32:00,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.69989, 0.45002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8003/9196 [17:58<1:02:40,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.72618, 0.48692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [20:25<00:00,  7.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 T loss: 6.61341. V loss: 4.84294. F1: [0.7473, 0.50389]. P: [0.75105, 0.53675] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2003/9196 [04:20<6:17:59,  3.15s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.78049, 0.55876]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4003/9196 [08:41<4:33:56,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.79384, 0.58838]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6003/9196 [13:06<2:47:26,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.80103, 0.60817]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8003/9196 [17:29<1:02:31,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.80639, 0.63857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [19:57<00:00,  7.68it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 T loss: 4.13323. V loss: 3.68842. F1: [0.80875, 0.63045]. P: [0.79989, 0.64341] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2003/9196 [04:27<6:15:09,  3.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.82103, 0.64781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4003/9196 [08:48<4:28:45,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.82164, 0.66638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6003/9196 [13:08<2:39:19,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.83035, 0.67798]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8003/9196 [17:25<1:00:39,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.8352, 0.68557]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [19:49<00:00,  7.73it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 T loss: 3.35514. V loss: 3.08872. F1: [0.84296, 0.69312]. P: [0.83396, 0.70252] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [26:50<4:12:30,  2.11s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.85194, 0.70102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4003/9196 [30:21<2:18:18,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.85008, 0.70382]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6003/9196 [34:18<2:43:12,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.84822, 0.71657]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8003/9196 [38:46<1:03:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.85833, 0.72639]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [41:19<00:00,  3.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 T loss: 2.91102. V loss: 2.77387. F1: [0.86056, 0.7215]. P: [0.85924, 0.72444] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [04:37<11:33:42,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.86929, 0.73768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [09:18<5:57:19,  4.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.86356, 0.74011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [13:56<5:07:52,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.87261, 0.74341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [18:34<1:55:36,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.87052, 0.74563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [21:10<00:00,  7.24it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 T loss: 2.59942. V loss: 2.52903. F1: [0.87302, 0.7456]. P: [0.86696, 0.75424] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [04:41<8:11:37,  4.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.86764, 0.75526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [09:22<5:54:18,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.88441, 0.76443]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6002/9196 [14:03<3:38:29,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.87482, 0.76742]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8002/9196 [18:45<1:21:35,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.88295, 0.77152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [21:21<00:00,  7.18it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 T loss: 2.36366. V loss: 2.31394. F1: [0.88486, 0.76933]. P: [0.88552, 0.77066] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [04:41<8:12:56,  4.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.88251, 0.77883]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [09:27<5:54:43,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.89717, 0.77904]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [14:08<5:11:34,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.89149, 0.78166]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8002/9196 [18:49<1:21:39,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.89935, 0.78397]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [21:25<00:00,  7.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10 T loss: 2.16952. V loss: 2.14979. F1: [0.89476, 0.78544]. P: [0.90153, 0.78891] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [04:41<8:12:25,  4.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.89517, 0.79322]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [09:22<5:58:38,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.89351, 0.79669]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6002/9196 [14:03<3:39:00,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.90727, 0.79766]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8002/9196 [18:49<1:25:25,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.90441, 0.80098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [21:27<00:00,  7.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/10 T loss: 2.00815. V loss: 2.05332. F1: [0.90019, 0.79307]. P: [0.89525, 0.79748] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1462/9196 [03:12<16:56,  7.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhierarchical\u001b[39m(\u001b[38;5;28minput\u001b[39m, targets):\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m models.penalized_cross_entropy(\u001b[38;5;28minput\u001b[39m, targets, penalty_matrix)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m model = \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMAMBA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m matrix = models.confusion_matrix(model, test_data, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, mapping)\n\u001b[32m    140\u001b[39m plt.matshow(matrix)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mbenchmark\u001b[39m\u001b[34m(classifier, name, max_epochs, loss_fn)\u001b[39m\n\u001b[32m     52\u001b[39m     optimizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     53\u001b[39m a = time()\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m losses, f1, validation_losses = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_n_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msupervised\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m b = time()\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(b\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39ma)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/maitrise/stelaro/stelaro/models/__init__.py:624\u001b[39m, in \u001b[36mClassifier.train\u001b[39m\u001b[34m(self, train_loader, validate_loader, optimizer, max_n_epochs, patience, loss_function, loss_function_type, evaluation_interval)\u001b[39m\n\u001b[32m    622\u001b[39m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m    623\u001b[39m optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m losses[-\u001b[32m1\u001b[39m] += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m progress \u001b[38;5;129;01mand\u001b[39;00m progress % evaluation_interval == \u001b[32m0\u001b[39m:\n\u001b[32m    626\u001b[39m     ps = estimate_precision(\u001b[38;5;28mself\u001b[39m, validate_loader, \u001b[38;5;28mself\u001b[39m.device, \u001b[38;5;28mself\u001b[39m.mapping)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import torch\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel, MambaConfig\n",
    "from mamba_ssm import Mamba\n",
    "from torch import nn\n",
    "\n",
    "# 256, 128, 2, 16, 8, 2, 0.1, batch 128, noClip, CEL\n",
    "# F1: [0.94682, 0.88288]\n",
    "# Precision: [0.94012, 0.88521]\n",
    "\n",
    "# 256, 64, 2, 16, 8, 2, 0.1, batch 128, noClip, CEL\n",
    "# F1: [0.92456, 0.8333]\n",
    "# Precision: [0.93198, 0.84133]\n",
    "\n",
    "# 256, 128, 2, 16, 8, 2, 0.1, batch 64, noClip, CEL\n",
    "# F1: [0.94531, 0.88431]\n",
    "# Precision: [0.94236, 0.88785]\n",
    "\n",
    "# 256, 128, 2, 16, 8, 3, 0.1, batch 128, noClip, CEL*\n",
    "# F1: [0.95005, 0.88783]\n",
    "# Precision: [0.94598, 0.89011]\n",
    "\n",
    "# 256, 256, 2, 16, 8, 2, 0.1, batch 64, 5 epochs, noClip, CEL\n",
    "# F1: [0.95149, 0.88721]\n",
    "# Precision: [0.95105, 0.88929]\n",
    "\n",
    "# 256, 128, 2, 16, 16, 2, 0.1, batch 128, noClip, CEL\n",
    "# F1: [0.95237, 0.88463]\n",
    "# Precision: [0.95195, 0.88635]\n",
    "\n",
    "# 256, 128, 2, 16, 16, 2, 0.1, batch 128, clip, focal mean\n",
    "# F1: [0.94285, 0.87642]\n",
    "# Precision: [0.93603, 0.87868]\n",
    "\n",
    "# 256, 128, 2, 16, 16, 2, 0.1, batch 128, clip, focal sum\n",
    "# F1: [0.94163, 0.87185]\n",
    "# Precision: [0.93829, 0.87553]\n",
    "\n",
    "# 256, 128, 2, 16, 16, 2, 0.1, batch 128, clip, penalty sum\n",
    "# F1: [0.91501, 0.68972]\n",
    "# Precision: [0.90453, 0.7091]\n",
    "\n",
    "# 256, 128, 2, 16, 8, 2, 0.1, batch 128, noClip, focal sum\n",
    "# F1: [0.93204, 0.85329]\n",
    "# Precision: [0.93095, 0.85767]\n",
    "\n",
    "# 256, 128, 3, 16, 8, 2, 0.1, batch 128, noClip, CEL\n",
    "# F1: [0.90227, 0.80133]\n",
    "# Precision: [0.89234, 0.80588]\n",
    "\n",
    "\n",
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        N: int,\n",
    "        num_classes: int,\n",
    "        vocab_size: int = 256,\n",
    "        d_model: int = 128,\n",
    "        n_layers: int = 3,\n",
    "        d_state: int = 16,\n",
    "        d_conv: int = 4,\n",
    "        expand: int = 2,\n",
    "        pooling = \"mean\",\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            Mamba(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        self.pooling = pooling\n",
    "\n",
    "    def forward(self, x: torch.LongTensor) -> torch.Tensor:\n",
    "        h = self.embedding(x).to(dtype=torch.get_default_dtype())\n",
    "        # h = h.to(torch.float16)\n",
    "        for block in self.layers:\n",
    "            h = block(h)   # each Mamba block returns [B, L, d_model]\n",
    "        h = self.norm(h)\n",
    "        pooled = h.mean(dim=1)  # [B, d_model]\n",
    "        pooled = self.dropout(pooled)\n",
    "        logits = self.classifier(pooled)  # [B, num_classes]\n",
    "        return logits\n",
    "\n",
    "\n",
    "classifier = models.Classifier(\n",
    "    LENGTH // 4,\n",
    "    mapping,\n",
    "    \"cuda\",\n",
    "    MambaSequenceClassifier,\n",
    "    format.to_tetramers,\n",
    "    True\n",
    ")\n",
    "# classifier.model = classifier.model.to(torch.float16)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "def focal_loss(inputs, targets, alpha=1, gamma=2):\n",
    "    num_classes = inputs.shape[1]\n",
    "    targets = F.one_hot(targets, num_classes=num_classes).float()\n",
    "    bce_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "    pt = exp(-bce_loss)  # Convert BCE loss to probability\n",
    "    focal_loss = alpha * (1 - pt) ** gamma * bce_loss  # Apply focal adjustment\n",
    "    return focal_loss.sum()\n",
    "\n",
    "\n",
    "def create_penalty_matrix(mapping):\n",
    "    d = len(mapping)\n",
    "    t = torch.zeros((d, d))\n",
    "    n_ranks = len(mapping['0'])\n",
    "    for i in mapping:\n",
    "        for j in range(d):\n",
    "            j = str(j)\n",
    "            union_length = 0\n",
    "            for a, b in zip(mapping[i], mapping[j]):\n",
    "                if a == b:\n",
    "                    union_length += 1\n",
    "                else:\n",
    "                    break\n",
    "            penalty = ((n_ranks - union_length) / n_ranks) ** 0.5\n",
    "            t[int(i), int(j)] = penalty\n",
    "    return t\n",
    "penalty_matrix = create_penalty_matrix(mapping).to(\"cuda\")\n",
    "def penalty_cross_entropy(y_pred, y_true):\n",
    "    probs = F.softmax(y_pred, dim=-1)  # [B, M]\n",
    "    penalty_rows = penalty_matrix[y_true]  # [B, M]\n",
    "    loss = -torch.sum((1 - penalty_rows) * torch.log(probs + 1e-12), dim=-1)\n",
    "    return loss.sum()\n",
    "def hierarchical(input, targets):\n",
    "    return models.penalized_cross_entropy(input, targets, penalty_matrix)\n",
    "\n",
    "\n",
    "model = benchmark(\n",
    "    classifier,\n",
    "    \"MAMBA\",\n",
    "    max_epochs=10,\n",
    "    loss_fn=nn.CrossEntropyLoss()\n",
    ")\n",
    "matrix = models.confusion_matrix(model, test_data, \"cuda\", mapping)\n",
    "plt.matshow(matrix)\n",
    "plt.show()\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=500, threshold=np.inf)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d470f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.90227, 0.80133]\n",
      "Precision: [0.89234, 0.80588]\n"
     ]
    }
   ],
   "source": [
    "result = models.evaluate(classifier, test_data, \"cuda\", mapping)\n",
    "rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "print(f\"F1: {rounded_result}\")\n",
    "result = models.evaluate_precision(classifier, test_data, \"cuda\", mapping)\n",
    "rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "print(f\"Precision: {rounded_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a809338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': ['Archaea', 'Methanobacteriota'], '1': ['Archaea', 'Nitrososphaerota'], '2': ['Archaea', 'Thermoplasmatota'], '3': ['Archaea', 'Thermoproteota'], '4': ['Bacteria', 'Actinomycetota'], '5': ['Bacteria', 'Aquificota'], '6': ['Bacteria', 'Bacillota'], '7': ['Bacteria', 'Bacteroidota'], '8': ['Bacteria', 'Bdellovibrionota'], '9': ['Bacteria', 'Campylobacterota'], '10': ['Bacteria', 'Chlamydiota'], '11': ['Bacteria', 'Chlorobiota'], '12': ['Bacteria', 'Chloroflexota'], '13': ['Bacteria', 'Cyanobacteriota'], '14': ['Bacteria', 'Deinococcota'], '15': ['Bacteria', 'Fusobacteriota'], '16': ['Bacteria', 'Gemmatimonadota'], '17': ['Bacteria', 'Lentisphaerota'], '18': ['Bacteria', 'Mycoplasmatota'], '19': ['Bacteria', 'Myxococcota'], '20': ['Bacteria', 'Nitrospirota'], '21': ['Bacteria', 'Planctomycetota'], '22': ['Bacteria', 'Pseudomonadota'], '23': ['Bacteria', 'Rhodothermota'], '24': ['Bacteria', 'Spirochaetota'], '25': ['Bacteria', 'Thermodesulfobacteriota'], '26': ['Bacteria', 'Thermotogota'], '27': ['Bacteria', 'Verrucomicrobiota'], '28': ['Eukaryota', 'Apicomplexa'], '29': ['Eukaryota', 'Arthropoda'], '30': ['Eukaryota', 'Ascomycota'], '31': ['Eukaryota', 'Bacillariophyta'], '32': ['Eukaryota', 'Basidiomycota'], '33': ['Eukaryota', 'Chlorophyta'], '34': ['Eukaryota', 'Chordata'], '35': ['Eukaryota', 'Euglenozoa'], '36': ['Eukaryota', 'Evosea'], '37': ['Eukaryota', 'Mollusca'], '38': ['Eukaryota', 'Nematoda'], '39': ['Eukaryota', 'Platyhelminthes'], '40': ['Eukaryota', 'Rhodophyta'], '41': ['Eukaryota', 'Streptophyta'], '42': ['Viruses', 'Artverviricota'], '43': ['Viruses', 'Kitrinoviricota'], '44': ['Viruses', 'Negarnaviricota'], '45': ['Viruses', 'Peploviricota'], '46': ['Viruses', 'Pisuviricota'], '47': ['Viruses', 'Taleaviricota'], '48': ['Viruses', 'Uroviricota']}\n",
      "tensor([[0.0000, 0.5000, 0.5000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [0.5000, 0.0000, 0.5000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [0.5000, 0.5000, 0.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        ...,\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 0.0000, 0.5000, 0.5000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 0.5000, 0.0000, 0.5000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 0.5000, 0.5000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(mapping)\n",
    "m = models.create_penalty_matrix(mapping)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af506c",
   "metadata": {},
   "source": [
    "# 1-NT Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32616ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 69_873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5001/9196 [28:50<8:21:51,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.87169, 0.7341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [1:36:26<00:00,  1.59it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 28032 data points.\n",
      "1/10 T loss: 13.99071. V loss: 10.32095. F1: [0.86647, 0.74595]. P: [0.88074, 0.77692] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5000/9196 [1:05:05<51:28,  1.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 38144 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5001/9196 [1:05:36<11:29:05,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.90584, 0.8145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [1:57:10<00:00,  1.31it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 38144 data points.\n",
      "2/10 T loss: 8.43410. V loss: 8.98794. F1: [0.88082, 0.78494]. P: [0.89169, 0.80668] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 94/9196 [01:11<1:54:40,  1.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m logits\n\u001b[32m     43\u001b[39m classifier = models.Classifier(LENGTH, mapping, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, MambaSequenceClassifier, \u001b[38;5;28mformat\u001b[39m.to_digits)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m model = \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMAMBA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m matrix = models.confusion_matrix(model, test_data, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, mapping)\n\u001b[32m     50\u001b[39m plt.matshow(matrix)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mbenchmark\u001b[39m\u001b[34m(classifier, name, max_epochs)\u001b[39m\n\u001b[32m     51\u001b[39m     optimizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     52\u001b[39m a = time()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m losses, f1, validation_losses = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_n_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msupervised\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m b = time()\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(b\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39ma)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/maitrise/stelaro/stelaro/models/__init__.py:618\u001b[39m, in \u001b[36mClassifier.train\u001b[39m\u001b[34m(self, train_loader, validate_loader, optimizer, max_n_epochs, patience, loss_function, loss_function_type, evaluation_interval)\u001b[39m\n\u001b[32m    616\u001b[39m loss.backward()\n\u001b[32m    617\u001b[39m optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m losses[-\u001b[32m1\u001b[39m] += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m progress \u001b[38;5;129;01mand\u001b[39;00m progress % evaluation_interval == \u001b[32m0\u001b[39m:\n\u001b[32m    620\u001b[39m     ps = estimate_precision(\u001b[38;5;28mself\u001b[39m, validate_loader, \u001b[38;5;28mself\u001b[39m.device, \u001b[38;5;28mself\u001b[39m.mapping)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import torch\n",
    "from mamba_ssm import Mamba\n",
    "from torch import nn\n",
    "\n",
    "# 256, 64, 2, 16, 8, 2, 0.1, batch 128\n",
    "# F1: [0.88082, 0.78494]\n",
    "# P: [0.89169, 0.80668]\n",
    "\n",
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        N: int,\n",
    "        num_classes: int,\n",
    "        vocab_size: int = 4,\n",
    "        d_model: int = 64,\n",
    "        n_layers: int = 2,\n",
    "        d_state: int = 16,\n",
    "        d_conv: int = 8,\n",
    "        expand: int = 2,\n",
    "        pooling = \"mean\",\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            Mamba(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        self.pooling = pooling\n",
    "\n",
    "    def forward(self, x: torch.LongTensor) -> torch.Tensor:\n",
    "        h = self.embedding(x).to(dtype=torch.get_default_dtype())\n",
    "        for block in self.layers:\n",
    "            h = block(h)   # each Mamba block returns [B, L, d_model]\n",
    "        h = self.norm(h)\n",
    "        pooled = h.mean(dim=1)  # [B, d_model]\n",
    "        pooled = self.dropout(pooled)\n",
    "        logits = self.classifier(pooled)  # [B, num_classes]\n",
    "        return logits\n",
    "\n",
    "\n",
    "classifier = models.Classifier(LENGTH, mapping, \"cuda\", MambaSequenceClassifier, format.to_digits)\n",
    "model = benchmark(\n",
    "    classifier,\n",
    "    \"MAMBA\",\n",
    "    max_epochs=10,\n",
    ")\n",
    "matrix = models.confusion_matrix(model, test_data, \"cuda\", mapping)\n",
    "plt.matshow(matrix)\n",
    "plt.show()\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=500, threshold=np.inf)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edcb9cf",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77852ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain pretraining data\n",
    "DATA_DIRECTORY = \"../data/\"\n",
    "BERTAX_DIRECTORY = DATA_DIRECTORY + \"bertax/pretraining/\"\n",
    "BERTAX_DATASET_DIRECTORY = BERTAX_DIRECTORY + \"pretraining_dataset/data/fass2/projects/fk_read_classification/dna_sequences/fragments/genomic_fragments_80/\"\n",
    "BERTAX_DOMAINS = (\n",
    "    \"Archaea_db.fa\",\n",
    "    \"Bacteria_db.fa\",\n",
    "    \"Eukaryota_db.fa\",\n",
    "    \"Viruses_db.fa\",\n",
    ")\n",
    "\n",
    "total = 0\n",
    "for domain in BERTAX_DOMAINS:\n",
    "    with open(BERTAX_DATASET_DIRECTORY + domain, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\">\"):\n",
    "                total += 1\n",
    "    print(f\"Domain: {domain}. Total: {total}\")\n",
    "\n",
    "x = np.zeros((total, 1500 // 4), dtype=np.uint8)\n",
    "mkdir(PROCESSED_PRETRAINING_DATA)\n",
    "i = 0\n",
    "for domain in BERTAX_DOMAINS:\n",
    "    with open(BERTAX_DATASET_DIRECTORY + domain, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line.startswith(\">\"):\n",
    "                sequence = line.strip().upper()\n",
    "                characters = set(sequence)\n",
    "                if len(characters) == 4:\n",
    "                    encoding = format.encode_tetramer(sequence)\n",
    "                    x[i] = encoding\n",
    "                    i += 1\n",
    "np.save(PROCESSED_PRETRAINING_DATA + \"/x.npy\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946663b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning:\n",
      "Number of parameters: 389_938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [03:41<9:12:55,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.80326, 0.64982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [07:23<6:36:08,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.85748, 0.70958]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [11:08<4:09:57,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.88819, 0.7525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [15:02<1:41:36,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.89519, 0.77108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [17:18<00:00,  8.86it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 T loss: 3.19294. V loss: 2.32218. F1: [0.89688, 0.77193]. P: [0.90517, 0.78354] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [04:06<7:58:51,  3.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.89802, 0.80257]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [08:26<6:06:06,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.90943, 0.80979]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6002/9196 [12:33<3:16:53,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.92629, 0.81882]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8002/9196 [16:39<1:16:15,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.90996, 0.82479]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [19:04<00:00,  8.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 T loss: 1.95762. V loss: 1.75689. F1: [0.92233, 0.82708]. P: [0.92497, 0.83141] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [03:59<7:22:55,  3.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.91814, 0.83478]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [08:01<5:21:18,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93004, 0.84943]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [12:09<4:51:13,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93896, 0.84498]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8002/9196 [16:12<1:16:59,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93467, 0.85354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [18:24<00:00,  8.32it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 T loss: 1.57684. V loss: 1.56207. F1: [0.93461, 0.84664]. P: [0.93917, 0.85025] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [04:02<8:10:50,  4.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93231, 0.85553]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [08:11<5:34:05,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93944, 0.85901]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4622/9196 [09:30<09:24,  8.10it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 132\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# classifier = models.Classifier(\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m#     LENGTH // 4,\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m#     mapping,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m \u001b[38;5;66;03m#     mlm_probability=0.25\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFine-tuning:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m model = \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMAMBA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\n\u001b[32m    139\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m matrix = models.confusion_matrix(model, test_data, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, mapping)\n\u001b[32m    141\u001b[39m plt.matshow(matrix)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mbenchmark\u001b[39m\u001b[34m(classifier, name, max_epochs, loss_fn, evaluation_interval, learning_rate)\u001b[39m\n\u001b[32m     54\u001b[39m     optimizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     55\u001b[39m a = time()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m losses, f1, validation_losses = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_n_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msupervised\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_interval\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m b = time()\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(b\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39ma)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/maitrise/stelaro/stelaro/models/__init__.py:778\u001b[39m, in \u001b[36mClassifier.train\u001b[39m\u001b[34m(self, train_loader, validate_loader, optimizer, max_n_epochs, patience, loss_function, loss_function_type, evaluation_interval)\u001b[39m\n\u001b[32m    776\u001b[39m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m    777\u001b[39m optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m losses[-\u001b[32m1\u001b[39m] += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m progress \u001b[38;5;129;01mand\u001b[39;00m progress % evaluation_interval == \u001b[32m0\u001b[39m:\n\u001b[32m    780\u001b[39m     ps = estimate_precision(\u001b[38;5;28mself\u001b[39m, validate_loader, \u001b[38;5;28mself\u001b[39m.device, \u001b[38;5;28mself\u001b[39m.mapping)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, AdamW\n",
    "import torch\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel, MambaConfig\n",
    "from mamba_ssm import Mamba\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# 128, 2, 16, 4, 2, mean, 0.1, noClip, pretraining: 10_000 -> 0.15 MLM\n",
    "# F1: [0.9365, 0.86395]\n",
    "# Precision: [0.93262, 0.87061]\n",
    "\n",
    "# 128, 2, 16, 4, 2, mean, 0.1, noClip, pretraining: 20_000 -> 0.15 MLM\n",
    "# Precision: [0.93845, 0.86496] (incomplete training - no difference with 10k steps)\n",
    "# Lowest MLM loss: 0.1352\n",
    "# Fine-tuning:\n",
    "#   Epoch 1: F1: [0.88529, 0.75644]. P: [0.89593, 0.76523]\n",
    "#   Epoch 2: F1: [0.91113, 0.81615]. P: [0.91365, 0.82102]\n",
    "\n",
    "# 128, 2, 16, 4, 2, mean, 0.1, noClip, pretraining: 100_000 -> 0.15 MLM\n",
    "# 1/10 T loss: 2.97148. V loss: 2.46173. F1: [0.87928, 0.75458]. P: [0.87739, 0.77189] Patience: 3\n",
    "# 2/10 T loss: 1.97898. V loss: 1.84719. F1: [0.91845, 0.82066]. P: [0.92227, 0.82479] Patience: 3\n",
    "# 5/10 T loss: 1.37992. V loss: 1.43371. F1: [0.9326, 0.86184]. P: [0.92561, 0.86369]\n",
    "\n",
    "# 128, 2, 16, 4, 2, mean, 0.1, noClip, pretraining: 50_000 new -> 0.15 MLM\n",
    "# 1/10 T loss: 3.11947. V loss: 2.29345. F1: [0.89625, 0.77654]. P: [0.89769, 0.78591] Patience: 3\n",
    "# 2/10 T loss: 2.04814. V loss: 1.93529. F1: [0.91427, 0.81052]. P: [0.913, 0.81998] Patience: 3\n",
    "# 3/10 T loss: 1.70350. V loss: 1.71731. F1: [0.92385, 0.83688]. P: [0.9214, 0.84447] Patience: 3\n",
    "\n",
    "# 128, 2, 16, 4, 2, mean, 0.1, noClip, pretraining: 40_000 new -> 0.15 MLM, lr = 0.0001\n",
    "# 1/10 T loss: 3.12365. V loss: 2.35835. F1: [0.8859, 0.76903]. P: [0.88096, 0.77557] Patience: 3\n",
    "# 2/10 T loss: 1.99888. V loss: 1.85153. F1: [0.9151, 0.8191]. P: [0.9125, 0.82259] Patience: 3\n",
    "# 3/10 T loss: 1.68860. V loss: 1.62224. F1: [0.92761, 0.84333]. P: [0.92996, 0.84681] Patience: 3\n",
    "\n",
    "# 128, 3 (norms), 16, 4, 2, mean, 0.1, clip, pretraining: 10_000 new -> 0.2 MLM, lr = 0.0001\n",
    "\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_state, d_conv, expand):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.mamba = Mamba(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pre-norm + residual connection\n",
    "        return x + self.mamba(self.norm(x))\n",
    "\n",
    "\n",
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        N: int,\n",
    "        num_classes: int,\n",
    "        vocab_size: int = 256,\n",
    "        d_model: int = 128,\n",
    "        n_layers: int = 3,\n",
    "        d_state: int = 16,\n",
    "        d_conv: int = 4,\n",
    "        expand: int = 2,\n",
    "        pooling = \"mean\",\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            # Mamba(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand)\n",
    "            MambaBlock(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Conv1d(128, 256, kernel_size=5, padding=2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Flatten(),\n",
    "        #     nn.Linear(N * 256, num_classes),\n",
    "        # )\n",
    "\n",
    "        self.pooling = pooling\n",
    "        self.mlm_head = nn.Linear(d_model, vocab_size + 1)\n",
    "        self.mlm_head.weight = self.embedding.weight\n",
    "\n",
    "    def forward(self, x: torch.LongTensor, mlm=None) -> torch.Tensor:\n",
    "        h = self.embedding(x)#.to(dtype=torch.get_default_dtype())\n",
    "        for block in self.layers:\n",
    "            h = block(h)   # each Mamba block returns [B, L, d_model]\n",
    "        h = self.norm(h)\n",
    "        if mlm is not None:\n",
    "            logits = self.mlm_head(h)  # [B, L, vocab_size + 1]\n",
    "            return logits\n",
    "        else:\n",
    "            # pooled = h[:, 0]\n",
    "            pooled = h.mean(dim=1)  # [B, d_model]\n",
    "            pooled = self.dropout(pooled)\n",
    "            # pooled = pooled.permute(0, 2, 1)\n",
    "            logits = self.classifier(pooled)  # [B, num_classes]\n",
    "            return logits\n",
    "\n",
    "\n",
    "classifier = models.Classifier(\n",
    "    LENGTH // 4,\n",
    "    mapping,\n",
    "    \"cuda\",\n",
    "    MambaSequenceClassifier,\n",
    "    format.to_tetramers,\n",
    "    True\n",
    ")\n",
    "\n",
    "print(\"Pretraining:\")\n",
    "optimizer = AdamW(classifier.get_parameters(), lr=0.001)\n",
    "pretraining_data = DataLoader(\n",
    "    models.SyntheticTetramerDataset(PROCESSED_PRETRAINING_DATA, labels=False),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "classifier.pretrain(\n",
    "    pretraining_data,\n",
    "    optimizer,\n",
    "    10_000,\n",
    "    256,\n",
    "    patience=3,\n",
    "    mlm_probability=0.25\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning:\")\n",
    "model = benchmark(\n",
    "    classifier,\n",
    "    \"MAMBA\",\n",
    "    max_epochs=10,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    evaluation_interval=2000,\n",
    "    learning_rate=0.0001\n",
    ")\n",
    "matrix = models.confusion_matrix(model, test_data, \"cuda\", mapping)\n",
    "plt.matshow(matrix)\n",
    "plt.show()\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=500, threshold=np.inf)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d66c52",
   "metadata": {},
   "source": [
    "# Frozen Initial Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bc93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/maitrise/stelaro/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 500/19473 [02:17<1:24:53,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 500. Epoch: 1. MLM loss: 5.3348. Patience: 3\n",
      "Average entropy: 5.2994. Correct predictions: 146417 / 7200686 (2.0334 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1000/19473 [04:32<1:23:29,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000. Epoch: 1. MLM loss: 5.2464. Patience: 3\n",
      "Average entropy: 5.1635. Correct predictions: 176006 / 7201752 (2.4439 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1500/19473 [06:47<1:20:56,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1500. Epoch: 1. MLM loss: 5.2245. Patience: 3\n",
      "Average entropy: 5.1515. Correct predictions: 180012 / 7202400 (2.4993 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2000/19473 [09:03<1:19:05,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2000. Epoch: 1. MLM loss: 5.2166. Patience: 3\n",
      "Average entropy: 5.1437. Correct predictions: 181911 / 7201691 (2.5259 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2500/19473 [11:18<1:16:59,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2500. Epoch: 1. MLM loss: 5.2045. Patience: 3\n",
      "Average entropy: 5.1177. Correct predictions: 188454 / 7200632 (2.6172 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3000/19473 [13:34<1:14:48,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3000. Epoch: 1. MLM loss: 5.2015. Patience: 3\n",
      "Average entropy: 5.0864. Correct predictions: 188014 / 7198629 (2.6118 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3500/19473 [15:52<1:13:28,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3500. Epoch: 1. MLM loss: 5.1959. Patience: 3\n",
      "Average entropy: 5.0592. Correct predictions: 191481 / 7199685 (2.6596 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4000/19473 [18:12<1:11:24,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4000. Epoch: 1. MLM loss: 5.1916. Patience: 3\n",
      "Average entropy: 5.0214. Correct predictions: 192323 / 7200514 (2.671 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4500/19473 [20:30<1:09:24,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4500. Epoch: 1. MLM loss: 5.1874. Patience: 3\n",
      "Average entropy: 4.982. Correct predictions: 195279 / 7201607 (2.7116 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 5000/19473 [22:47<1:05:38,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000. Epoch: 1. MLM loss: 5.1855. Patience: 3\n",
      "Average entropy: 4.9465. Correct predictions: 196856 / 7199420 (2.7343 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5500/19473 [25:03<1:03:30,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5500. Epoch: 1. MLM loss: 5.1856. Patience: 3\n",
      "Average entropy: 4.8863. Correct predictions: 193157 / 7197670 (2.6836 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 6000/19473 [27:20<1:01:50,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6000. Epoch: 1. MLM loss: 5.1815. Patience: 2\n",
      "Average entropy: 4.8446. Correct predictions: 196546 / 7199389 (2.73 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6500/19473 [29:36<58:53,  3.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6500. Epoch: 1. MLM loss: 5.1813. Patience: 2\n",
      "Average entropy: 4.8327. Correct predictions: 195325 / 7199206 (2.7131 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 7000/19473 [31:52<56:32,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7000. Epoch: 1. MLM loss: 5.1793. Patience: 2\n",
      "Average entropy: 4.7876. Correct predictions: 197887 / 7203391 (2.7471 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 7500/19473 [34:08<54:17,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7500. Epoch: 1. MLM loss: 5.1737. Patience: 2\n",
      "Average entropy: 4.7707. Correct predictions: 201147 / 7203915 (2.7922 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 8000/19473 [36:24<51:57,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8000. Epoch: 1. MLM loss: 5.1753. Patience: 2\n",
      "Average entropy: 4.7916. Correct predictions: 199828 / 7199650 (2.7755 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 8500/19473 [38:40<49:43,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8500. Epoch: 1. MLM loss: 5.1726. Patience: 1\n",
      "Average entropy: 4.7989. Correct predictions: 201632 / 7204012 (2.7989 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 9000/19473 [40:56<47:25,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9000. Epoch: 1. MLM loss: 5.1716. Patience: 1\n",
      "Average entropy: 4.8109. Correct predictions: 201587 / 7197654 (2.8007 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 9499/19473 [43:11<45:07,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9500. Epoch: 1. MLM loss: 5.1724. Patience: 1\n",
      "Average entropy: 4.8166. Correct predictions: 199399 / 7198504 (2.77 %).\n",
      "Overfitting; stopping early.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 9499/19473 [43:12<45:22,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning:\n",
      "Number of parameters: 1_006_514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:00<2:32:17,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<47:42:13, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.38086, 0.024069]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [05:00<36:44,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [05:31<21:22:18,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.88894, 0.71968]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [09:59<32:08,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [10:30<18:46:14,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.89917, 0.77478]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [19:26<23:13,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [19:57<13:33:00,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.90859, 0.80899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [28:53<14:15,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [29:24<8:19:37,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.92684, 0.8367]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [38:18<05:19,  3.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49280 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [38:49<3:07:08,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94329, 0.84941]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [44:10<00:00,  3.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48896 data points.\n",
      "1/10 T loss: 2.09147. V loss: 1.52797. F1: [0.9361, 0.84797]. P: [0.93469, 0.85665] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<4:32:45,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<47:59:59, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93459, 0.85684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [05:00<36:40,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [05:30<21:26:00,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93638, 0.87065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [09:59<32:10,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [10:29<18:45:37,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93604, 0.87131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [19:26<23:13,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [19:56<13:32:36,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94704, 0.8842]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [28:51<14:15,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [29:22<8:19:26,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95404, 0.88475]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [38:17<05:19,  3.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [38:47<3:06:54,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95537, 0.88783]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [44:06<00:00,  3.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n",
      "2/10 T loss: 1.21583. V loss: 1.16146. F1: [0.95251, 0.88446]. P: [0.95302, 0.88647] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<4:31:53,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<48:10:49, 18.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95787, 0.88899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [04:58<36:27,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49280 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [05:29<21:21:10,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95847, 0.89462]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [09:56<31:59,  3.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49408 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [10:26<18:46:36,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96287, 0.89578]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [14:25:05<22:45,  3.80it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 50176 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [14:25:35<13:33:11,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95869, 0.90057]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [14:34:29<14:13,  3.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49280 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [14:35:00<8:19:31,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96378, 0.89852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [14:43:55<05:20,  3.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [14:44:26<3:07:07,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96471, 0.90794]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [14:49:47<00:00,  5.81s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48640 data points.\n",
      "3/10 T loss: 0.95586. V loss: 0.99232. F1: [0.96211, 0.90281]. P: [0.96149, 0.90428] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<4:34:33,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48896 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<48:01:00, 18.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95758, 0.90146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [05:00<36:36,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [05:31<21:23:26,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.9612, 0.91112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [09:58<32:07,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [10:29<18:47:07,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95814, 0.91301]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [19:26<23:18,  3.71it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48896 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [19:56<13:33:46,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95792, 0.91185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [28:54<14:19,  3.72it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48896 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [29:25<8:19:55,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96328, 0.91479]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [38:21<05:20,  3.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [38:52<3:07:10,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96095, 0.90538]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [44:13<00:00,  3.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48768 data points.\n",
      "4/10 T loss: 0.80864. V loss: 0.87850. F1: [0.9678, 0.91474]. P: [0.97123, 0.91485] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<4:31:02,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48896 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<47:55:14, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.97193, 0.91423]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [05:00<36:38,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [05:30<21:23:10,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96637, 0.91351]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [09:59<32:15,  3.72it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48896 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [10:30<18:46:41,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96375, 0.91459]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [19:26<23:12,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49024 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [19:57<13:32:43,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96555, 0.91676]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [28:52<14:15,  3.74it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49280 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [29:22<8:19:37,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96588, 0.91138]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [38:17<05:19,  3.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49408 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [38:47<3:07:05,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96452, 0.91384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [44:06<00:00,  3.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48640 data points.\n",
      "5/10 T loss: 0.70491. V loss: 0.83079. F1: [0.96823, 0.91957]. P: [0.96798, 0.92231] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<4:34:52,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48896 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<47:58:49, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96932, 0.9238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [05:00<36:47,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48512 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [05:31<21:23:42,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96461, 0.9226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [09:59<32:07,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [10:30<18:46:06,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.97175, 0.92065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [19:25<23:11,  3.73it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 49152 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [19:55<13:32:50,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96995, 0.91807]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [28:52<14:21,  3.71it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48896 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [29:22<8:20:56,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.97114, 0.92386]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [38:20<05:22,  3.71it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48768 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [38:51<3:06:57,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.96805, 0.92264]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [44:12<00:00,  3.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 48384 data points.\n",
      "6/10 T loss: 0.62788. V loss: 0.80313. F1: [0.96974, 0.92273]. P: [0.97203, 0.92367] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:05<13:27:02,  5.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# classifier.model.freeze_base()\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFine-tuning:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m model = \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMAMBA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\n\u001b[32m    130\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m matrix = models.confusion_matrix(model, test_data, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, mapping)\n\u001b[32m    132\u001b[39m plt.matshow(matrix)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mbenchmark\u001b[39m\u001b[34m(classifier, name, max_epochs, loss_fn, evaluation_interval, learning_rate)\u001b[39m\n\u001b[32m     54\u001b[39m     optimizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     55\u001b[39m a = time()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m losses, f1, validation_losses = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_n_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msupervised\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_interval\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m b = time()\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(b\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39ma)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/maitrise/stelaro/stelaro/models/__init__.py:795\u001b[39m, in \u001b[36mClassifier.train\u001b[39m\u001b[34m(self, train_loader, validate_loader, optimizer, max_n_epochs, patience, loss_function, loss_function_type, evaluation_interval)\u001b[39m\n\u001b[32m    793\u001b[39m losses[-\u001b[32m1\u001b[39m] += loss.item()\n\u001b[32m    794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m progress \u001b[38;5;129;01mand\u001b[39;00m progress % evaluation_interval == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m progress \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m1\u001b[39m, evaluation_interval // \u001b[32m2\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     ps = \u001b[43mestimate_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m     ps = [\u001b[38;5;28mfloat\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m ps]\n\u001b[32m    797\u001b[39m     p_msg = [\u001b[38;5;28mfloat\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m ps]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/maitrise/stelaro/stelaro/models/__init__.py:503\u001b[39m, in \u001b[36mestimate_precision\u001b[39m\u001b[34m(classifier, loader, device, mapping, time_limit)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m no_grad():\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m         x_batch = \u001b[43mx_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m         predictions = classifier.predict(x_batch)\n\u001b[32m    505\u001b[39m         all_pred.append(predictions)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, AdamW\n",
    "import torch\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel, MambaConfig\n",
    "from mamba_ssm import Mamba\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_state, d_conv, expand):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.mamba = Mamba(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pre-norm + residual connection\n",
    "        return x + self.mamba(self.norm(x))\n",
    "\n",
    "\n",
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        N: int,\n",
    "        num_classes: int,\n",
    "        vocab_size: int = 256,\n",
    "        d_model: int = 128,\n",
    "        n_layers: int = 4,\n",
    "        d_state: int = 16,\n",
    "        d_conv: int = 4,\n",
    "        expand: int = 2,\n",
    "        pooling = \"mean\",\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, d_model)\n",
    "        self.first_layers = nn.ModuleList([\n",
    "            MambaBlock(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.last_layers = nn.ModuleList([\n",
    "            MambaBlock(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Conv1d(128, 256, kernel_size=5, padding=2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Flatten(),\n",
    "        #     nn.Linear(N * 256, num_classes),\n",
    "        # )\n",
    "\n",
    "        self.pooling = pooling\n",
    "        self.mlm_head = nn.Linear(d_model, vocab_size + 1)\n",
    "        # self.mlm_head.weight = self.embedding.weight\n",
    "\n",
    "    def forward(self, x: torch.LongTensor, mlm=None) -> torch.Tensor:\n",
    "        h = self.embedding(x)#.to(dtype=torch.get_default_dtype())\n",
    "        if mlm is not None:\n",
    "            for block in self.first_layers:\n",
    "                h = block(h)   # each Mamba block returns [B, L, d_model]\n",
    "            for block in self.last_layers:\n",
    "                h = block(h)   # each Mamba block returns [B, L, d_model]\n",
    "            h = self.norm(h)\n",
    "            logits = self.mlm_head(h)  # [B, L, vocab_size + 1]\n",
    "            return logits\n",
    "        else:\n",
    "            for block in self.first_layers:\n",
    "                h = block(h)   # each Mamba block returns [B, L, d_model]\n",
    "            for block in self.last_layers:\n",
    "                h = block(h)   # each Mamba block returns [B, L, d_model]\n",
    "            h = self.norm(h)\n",
    "            pooled = h.mean(dim=1)  # [B, d_model]\n",
    "            pooled = self.dropout(pooled)\n",
    "            # pooled = pooled.permute(0, 2, 1)\n",
    "            logits = self.classifier(pooled)  # [B, num_classes]\n",
    "            return logits\n",
    "\n",
    "    def freeze_base(self):\n",
    "        for block in self.first_layers:\n",
    "            for param in block.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def unfreeze_base(self):\n",
    "        for block in self.first_layers:\n",
    "            for param in block.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "\n",
    "classifier = models.Classifier(\n",
    "    LENGTH // 4,\n",
    "    mapping,\n",
    "    \"cuda\",\n",
    "    MambaSequenceClassifier,\n",
    "    format.to_tetramers,\n",
    "    True\n",
    ")\n",
    "\n",
    "print(\"Pretraining:\")\n",
    "optimizer = AdamW(classifier.get_parameters(), lr=0.001)\n",
    "pretraining_data = DataLoader(\n",
    "    models.SyntheticTetramerDataset(PROCESSED_PRETRAINING_DATA, labels=False),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "classifier.pretrain(\n",
    "    pretraining_data,\n",
    "    optimizer,\n",
    "    20_000,\n",
    "    256,\n",
    "    patience=3,\n",
    "    mlm_probability=0.3\n",
    ")\n",
    "# classifier.model.freeze_base()\n",
    "\n",
    "print(\"Fine-tuning:\")\n",
    "model = benchmark(\n",
    "    classifier,\n",
    "    \"MAMBA\",\n",
    "    max_epochs=10,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    evaluation_interval=2000,\n",
    "    learning_rate=0.0001\n",
    ")\n",
    "matrix = models.confusion_matrix(model, test_data, \"cuda\", mapping)\n",
    "plt.matshow(matrix)\n",
    "plt.show()\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=500, threshold=np.inf)\n",
    "print(matrix)\n",
    "\n",
    "\n",
    "# 128, 3 / 3, 16, 4, 2, mean, 0.1, clip, pretraining: None\n",
    "# 1/10 T loss: 3.08970. V loss: 1.81286. F1: [0.91764, 0.82083]. P: [0.9162, 0.82467] Patience: 3\n",
    "# 2/10 T loss: 1.49454. V loss: 1.34284. F1: [0.94197, 0.87123]. P: [0.94196, 0.87661] Patience: 3\n",
    "\n",
    "# 128, 3 / 3, 16, 4, 2, mean, 0.1, clip, pretraining: 5k, freeze\n",
    "# 1/10 T loss: 9.88273. V loss: 9.09895. F1: [0.35103, 0.10588]. P: [0.38429, 0.12499]\n",
    "\n",
    "# 128, 2 / 2, 16, 4, 2, mean, 0.1, clip, pretraining: 10k, freeze\n",
    "# 1/10 T loss: 3.26994. V loss: 2.42430. F1: [0.89472, 0.75593]. P: [0.89744, 0.76282] Patience: 3\n",
    "\n",
    "# 128, 2 / 2, 16, 4, 2, mean, 0.1, clip, pretraining: 20k, freeze\n",
    "# 1/10 T loss: 4.59330. V loss: 3.32864. F1: [0.84704, 0.67053]. P: [0.84721, 0.67978] Patience: 3\n",
    "# 2/10 T loss: 2.78251. V loss: 2.51102. F1: [0.88506, 0.74861]. P: [0.88034, 0.75483] Patience: 3\n",
    "\n",
    "# 128, 2 / 2, 16, 4, 2, mean, 0.1, clip, pretraining: 20k, no freeze, span\n",
    "# 1/10 T loss: 3.30888. V loss: 2.14662. F1: [0.90234, 0.79144]. P: [0.90968, 0.79664] Patience: 3\n",
    "# 2/10 T loss: 1.76234. V loss: 1.54726. F1: [0.93, 0.84993]. P: [0.92694, 0.85452] Patience: 3\n",
    "# 3/10 T loss: 1.34409. V loss: 1.35847. F1: [0.93591, 0.86929]. P: [0.93794, 0.87497] Patience: 3\n",
    "\n",
    "# 128, 2 / 2, 16, 4, 2, mean, 0.1, clip, pretraining: 10k, no freeze, span\n",
    "# 1/10 T loss: 3.32805. V loss: 1.91426. F1: [0.91257, 0.81601]. P: [0.91242, 0.81589] Patience: 3\n",
    "# 2/10 T loss: 1.67703. V loss: 1.49529. F1: [0.93111, 0.85618]. P: [0.9346, 0.86045] Patience: 3\n",
    "# 3/10 T loss: 1.33147. V loss: 1.36263. F1: [0.93998, 0.86843]. P: [0.93879, 0.87145] Patience: 3\n",
    "\n",
    "# 128, 2 / 2, 16, 4, 2, mean, 0.1, clip, pretraining: 40k, no freeze, span\n",
    "# 1/10 T loss: 2.66859. V loss: 1.88050. F1: [0.91414, 0.81202]. P: [0.90473, 0.82252] Patience: 3\n",
    "# 2/10 T loss: 1.59724. V loss: 1.41483. F1: [0.94162, 0.86189]. P: [0.94196, 0.86865] Patience: 3\n",
    "# 3/10 T loss: 1.28868. V loss: 1.25275. F1: [0.94469, 0.8754]. P: [0.94138, 0.87864] Patience: 3\n",
    "\n",
    "# 128, 2 / 2, 16, 4, 2, mean, 0.1, clip, pretraining: 20k, no freeze, all masked 15 %\n",
    "# 1/10 T loss: 2.53448. V loss: 1.84904. F1: [0.91666, 0.8147]. P: [0.90713, 0.82688] Patience: 3\n",
    "# 2/10 T loss: 1.52909. V loss: 1.40461. F1: [0.94339, 0.86156]. P: [0.9458, 0.86432] Patience: 3\n",
    "# 3/10 T loss: 1.23919. V loss: 1.23687. F1: [0.95087, 0.8776]. P: [0.95401, 0.87988] Patience: 3\n",
    "\n",
    "# 128, 3 / 3, 16, 4, 2, mean, 0.1, clip, pretraining: 20k, no freeze, all masked 10 %\n",
    "# 1/10 T loss: 2.03367. V loss: 1.45920. F1: [0.93885, 0.85342]. P: [0.93636, 0.86178] Patience: 3\n",
    "# 2/10 T loss: 1.20462. V loss: 1.13109. F1: [0.95273, 0.88658]. P: [0.95174, 0.88691] Patience: 3\n",
    "# 3/10 T loss: 0.97474. V loss: 1.03495. F1: [0.95888, 0.89874]. P: [0.95798, 0.90307] Patience: 3\n",
    "# 4/10 T loss: 0.84054. V loss: 0.89632. F1: [0.96534, 0.91211]. P: [0.96508, 0.91451] Patience: 3\n",
    "\n",
    "\n",
    "# 10 %\n",
    "# Number of parameters: 957_362\n",
    "#   0%|          | 1/9196 [00:00<2:32:11,  1.01it/s]\n",
    "# Halting evaluation after 60288 data points.\n",
    "#   0%|          | 2/9196 [00:31<47:15:32, 18.50s/it]\n",
    "# P: [0.33365, 0.01094]\n",
    "#  11%|█         | 1000/9196 [03:59<28:13,  4.84it/s]\n",
    "# Halting evaluation after 61824 data points.\n",
    "#  11%|█         | 1001/9196 [04:30<21:17:30,  9.35s/it]\n",
    "# P: [0.88623, 0.69175]\n",
    "#  22%|██▏       | 2000/9196 [07:58<25:29,  4.70it/s]\n",
    "# Halting evaluation after 58624 data points.\n",
    "#  22%|██▏       | 2001/9196 [08:29<18:41:39,  9.35s/it]\n",
    "# P: [0.90945, 0.75627]\n",
    "#  43%|████▎     | 4000/9196 [15:27<18:08,  4.77it/s]\n",
    "# Halting evaluation after 59264 data points.\n",
    "#  44%|████▎     | 4001/9196 [15:58<13:32:05,  9.38s/it]\n",
    "# P: [0.9099, 0.79962]\n",
    "\n",
    "# 5 %\n",
    "# Number of parameters: 957_362\n",
    "#   0%|          | 1/9196 [00:00<50:19,  3.04it/s]\n",
    "# Halting evaluation after 57088 data points.\n",
    "#   0%|          | 2/9196 [00:31<46:32:23, 18.22s/it]\n",
    "# P: [0.41815, 0.0070681]\n",
    "#  11%|█         | 1000/9196 [04:01<28:21,  4.82it/s]\n",
    "# Halting evaluation after 59776 data points.\n",
    "#  11%|█         | 1001/9196 [04:32<21:16:29,  9.35s/it]\n",
    "# P: [0.86172, 0.67681]\n",
    "#  22%|██▏       | 2000/9196 [07:59<24:53,  4.82it/s]\n",
    "# Halting evaluation after 57984 data points.\n",
    "#  22%|██▏       | 2001/9196 [08:30<18:40:29,  9.34s/it]\n",
    "# P: [0.87491, 0.73942]\n",
    "#  43%|████▎     | 4000/9196 [15:28<18:06,  4.78it/s]\n",
    "# Halting evaluation after 59648 data points.\n",
    "#  44%|████▎     | 4002/9196 [15:59<9:31:19,  6.60s/it]\n",
    "# P: [0.92555, 0.7918]\n",
    "#  65%|██████▌   | 6000/9196 [22:58<11:55,  4.47it/s]\n",
    "# Halting evaluation after 59392 data points.\n",
    "#  65%|██████▌   | 6001/9196 [23:28<8:18:01,  9.35s/it]\n",
    "# P: [0.91853, 0.82185]\n",
    "\n",
    "# 0 %\n",
    "# Number of parameters: 957_362\n",
    "#   0%|          | 2/9196 [00:30<46:04:33, 18.04s/it]\n",
    "# P: [0.35437, 0.014502]\n",
    "#  11%|█         | 1000/9196 [03:58<28:27,  4.80it/s]\n",
    "# Halting evaluation after 60032 data points.\n",
    "#  11%|█         | 1001/9196 [04:29<21:17:28,  9.35s/it]\n",
    "# P: [0.78984, 0.51625]\n",
    "#  22%|██▏       | 2000/9196 [07:57<25:02,  4.79it/s]\n",
    "# Halting evaluation after 60416 data points.\n",
    "#  22%|██▏       | 2001/9196 [08:28<18:42:27,  9.36s/it]\n",
    "# P: [0.83578, 0.62203]\n",
    "#  43%|████▎     | 4000/9196 [15:23<17:57,  4.82it/s]\n",
    "# Halting evaluation after 60416 data points.\n",
    "#  44%|████▎     | 4001/9196 [15:53<13:29:12,  9.35s/it]\n",
    "# P: [0.86769, 0.75943]\n",
    "#  65%|██████▌   | 6000/9196 [22:51<11:10,  4.77it/s]\n",
    "# Halting evaluation after 59392 data points.\n",
    "#  65%|██████▌   | 6001/9196 [23:21<8:18:22,  9.36s/it]\n",
    "# P: [0.89947, 0.80061]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40b5c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.97157, 0.92366]\n",
      "Precision: [0.97456, 0.92527]\n"
     ]
    }
   ],
   "source": [
    "result = models.evaluate(classifier, test_data, \"cuda\", mapping)\n",
    "rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "print(f\"F1: {rounded_result}\")\n",
    "result = models.evaluate_precision(classifier, test_data, \"cuda\", mapping)\n",
    "rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "print(f\"Precision: {rounded_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b88333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1771.   11.   36.    6.    7.    1.   27.   11.    1.    4.    2.    3.    0.    0.    1.    1.    2.    0.    1.    1.    1.   10.    3.    7.    9.    2.   39.    3.    6.    3.    3.    2.    0.    1.    0.    0.    0.    1.    2.    0.    0.    8.    1.    0.    1.    3.    0.    0.    9.]\n",
      " [   5. 1914.    7.    2.    2.    0.    4.   13.    2.    1.    1.    0.    1.    0.    0.    0.    0.    0.    4.    0.    0.    0.    0.    0.    2.    4.    1.    2.    2.    1.    5.    2.    1.    2.    0.    1.    0.    2.    3.    1.    1.    9.    0.    0.    0.    2.    1.    0.    2.]\n",
      " [  16.   25. 1901.    4.    0.    0.   14.   13.    2.    0.    2.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.    0.    0.    0.    4.    2.    0.    5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    1.    1.    0.    1.    4.    0.    0.    1.]\n",
      " [  49.    4.   17. 1833.    0.    0.   20.    0.    6.    4.    5.    0.    0.    0.    2.    0.    0.    0.    2.    0.    0.    0.    0.    0.    2.    0.   25.    0.    3.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    6.    0.    0.    0.    8.    1.    5.    6.]\n",
      " [   3.    1.    0.    0. 1793.    0.    7.    4.    4.    0.    0.    0.    1.    1.    2.    0.   11.    0.    0.   22.    3.   24.   35.   15.    0.   10.    0.   16.    1.    0.    0.    0.    1.    1.    0.    1.    0.    1.    0.    0.    0.    2.    0.    0.    0.    4.    0.    0.   37.]\n",
      " [   2.    0.    0.    2.    0. 1887.   29.    8.    3.   16.    2.    0.    0.    0.    0.    2.    0.    0.    1.    0.    0.    0.    1.    0.    3.    1.   40.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  12.    4.    6.    2.    8.    6. 1602.   57.   19.   17.   31.    2.    8.    6.    0.   21.    1.    2.   12.    1.    2.   20.   27.    4.   19.   21.   29.    1.    5.    5.    2.    1.    1.    6.    1.    0.    0.    0.    1.    0.    0.    4.    0.    0.    0.    5.    0.    1.   28.]\n",
      " [   6.    7.    2.    1.    2.    0.   63. 1757.    7.    5.   20.    1.    5.    2.    1.    4.    1.    1.    7.    0.    1.   22.   25.    0.   15.    5.    4.    7.    5.    6.    1.    0.    0.    1.    0.    1.    0.    0.    2.    1.    0.    2.    0.    0.    0.    0.    0.    0.   10.]\n",
      " [   0.    1.    0.    0.    3.    0.    5.    4. 1946.    2.    7.    0.    0.    1.    0.    2.    0.    0.    2.    0.    1.    2.    0.    0.    4.    5.    0.    1.    1.    2.    0.    0.    0.    2.    0.    0.    0.    0.    1.    0.    0.    3.    0.    0.    0.    1.    0.    0.    4.]\n",
      " [   1.    0.    0.    0.    0.    0.   12.    3.   13. 1923.    3.    0.    0.    0.    1.   11.    0.    0.   11.    0.    0.    0.    2.    0.    7.    1.    3.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    3.    0.    0.    1.    0.    0.    0.    0.    0.    0.    4.]\n",
      " [   0.    2.    0.    0.    0.    0.    4.    8.    7.    1. 1962.    0.    0.    1.    0.    1.    0.    0.    0.    0.    0.    1.    4.    0.    3.    1.    0.    0.    0.    1.    1.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    1.    0.    0.]\n",
      " [   4.    1.    4.    0.    1.    0.    7.   12.    3.    0.    1. 1855.    5.    1.    0.    3.    0.    3.    0.    0.    4.   14.   18.    0.    3.   31.    2.   22.    0.    2.    0.    1.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.]\n",
      " [   3.    4.    0.    0.    4.    0.   31.   28.    1.    1.    8.    2. 1804.    4.    2.    0.    1.    0.    0.    0.   13.   11.   36.    1.    2.   11.    0.    7.    2.    1.    2.    0.    0.    0.    1.    0.    0.    1.    0.    1.    2.    0.    2.    0.    0.    3.    0.    0.   11.]\n",
      " [   0.    5.    0.    0.   12.    0.   16.    9.   11.    1.   26.    0.    6. 1842.    1.    3.    0.    0.    8.    0.    2.    4.   15.    2.    3.    1.    4.    1.    1.    3.    1.    1.    0.    3.    0.    0.    0.    0.    1.    1.    0.    3.    1.    0.    1.    3.    1.    0.    8.]\n",
      " [   1.    0.    0.    0.   21.    0.    5.    1.    2.    0.    0.    0.    1.    5. 1877.    0.    1.    0.    0.    4.    3.   15.   30.   11.    0.    6.    0.    6.    2.    0.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    1.    0.    0.    5.]\n",
      " [   2.    2.    0.    0.    0.    0.  127.    3.    2.   51.    1.    0.    0.    0.    0. 1730.    0.    1.   17.    0.    0.    0.    3.    0.   15.    0.   27.    0.    2.    0.    1.    0.    0.    0.    1.    0.    0.    0.    1.    0.    0.    2.    1.    0.    0.    0.    0.    0.   11.]\n",
      " [   2.    0.    0.    0.   21.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. 1918.    0.    0.   28.    7.    9.    9.    0.    0.    0.    0.    2.    0.    0.    0.    0.    0.    0.    0.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.]\n",
      " [   1.    0.    0.    0.    2.    0.   14.    6.    3.    0.    2.   16.    0.    0.    0.    0.    0. 1922.    0.    0.    1.    5.    3.    0.    4.    7.    0.   13.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    2.    0.    0.    1.    0.   30.   11.    5.   14.    0.    0.    0.    0.    0.    7.    0.    0. 1900.    0.    0.    0.    3.    0.   14.    0.    3.    0.    0.    3.    0.    0.    0.    2.    0.    0.    2.    0.    0.    0.    0.    1.    0.    0.    0.    0.    1.    0.    1.]\n",
      " [   1.    0.    0.    0.   33.    0.   21.    0.    0.    0.    0.    0.    0.    3.    0.    0.   14.    0.    0. 1883.    1.    6.   10.   13.    0.    1.    0.    0.    1.    0.    0.    0.    0.    2.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    9.    0.    0.    1.]\n",
      " [   0.    0.    0.    0.   12.    0.    2.    4.    1.    0.    2.    1.    1.    0.    1.    0.    5.    0.    0.    1. 1858.   41.   21.    4.    1.   12.    0.   19.    0.    1.    5.    2.    0.    1.    1.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    1.    0.    0.    2.]\n",
      " [   6.    0.    0.    0.   10.    0.    5.    9.    0.    0.    1.    1.    0.    1.    2.    1.    1.    0.    0.    2.   13. 1911.    6.   11.    0.    4.    3.    9.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.]\n",
      " [   1.    4.    2.    2.   43.    0.   61.   37.   23.   11.   26.   12.   19.   23.    5.    2.    8.    1.    9.    0.   26.   21. 1475.    5.   14.   66.    5.   22.    3.    4.    4.    1.    1.    1.    0.    1.    0.    1.    1.    0.    2.    2.    0.    0.    0.    4.    0.    0.   52.]\n",
      " [   1.    1.    0.    0.   11.    0.    3.    2.    0.    0.    0.    1.    0.    0.    2.    0.    3.    0.    0.    0.   15.    9.   10. 1920.    0.    4.    0.    2.    2.    0.    6.    0.    0.    2.    1.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    4.    0.    0.    0.]\n",
      " [   3.    2.    0.    0.    0.    0.   24.    7.    5.    8.    1.    1.    0.    0.    0.    4.    0.    1.    1.    0.    0.    5.    2.    0. 1920.    1.    4.    0.    2.    2.    0.    0.    0.    1.    0.    0.    0.    0.    1.    0.    0.    2.    0.    0.    0.    1.    0.    0.    2.]\n",
      " [   2.    2.    3.    0.   14.    3.   19.    8.    0.    0.    1.   11.    1.    6.    1.    0.    1.    4.    0.    0.   15.   30.   25.    6.    1. 1819.    1.   17.    2.    2.    1.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    1.    1.    0.    0.    0.    0.    0.    2.]\n",
      " [  12.    7.    9.    2.    0.    0.   21.    7.    1.    3.    2.    0.    0.    0.    2.    5.    0.    0.    3.    0.    0.    3.    0.    0.   14.    1. 1891.    0.    3.    3.    0.    1.    0.    0.    0.    0.    0.    0.    3.    0.    0.    1.    0.    0.    0.    0.    0.    1.    5.]\n",
      " [   0.    2.    0.    0.    3.    0.   15.   11.    1.    0.    0.    1.    0.    0.    0.    0.    2.    7.    0.    0.   12.   26.    7.    3.    1.   26.    1. 1882.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   1.   15.    3.    0.    2.    0.    3.    3.    5.    0.    1.    0.    0.    1.    0.    2.    0.    0.    1.    1.    0.    1.    0.    0.    0.    0.    1.    0. 1790.   25.   10.    5.    4.    4.    1.   29.    3.    2.   12.    6.    8.   26.    2.    0.    0.   30.    2.    0.    1.]\n",
      " [   2.    1.    0.    0.    0.    0.    3.    5.    1.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    2.    1.    1.    1.    0.    0.    0.   13. 1836.    7.    7.    0.    4.    1.    2.    0.   18.   21.   29.    0.   23.    2.    0.    1.   16.    0.    0.    1.]\n",
      " [   2.   18.    2.    0.    5.    0.    3.    3.    2.    1.    1.    0.    1.    1.    0.    0.    0.    0.    0.    0.    9.    2.    1.    5.    0.    3.    0.    1.   37.   37. 1591.   36.  106.    3.    0.    7.    2.    5.   16.   10.    7.   48.    0.    4.    0.   19.    4.    0.    8.]\n",
      " [   0.    1.    0.    0.    1.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.    4.    0.    0.    0.    1.    0.    0.    2.    7.   30. 1893.   13.    9.    0.    2.    0.    1.    7.    5.    3.    9.    1.    0.    0.    4.    4.    0.    0.]\n",
      " [   2.    1.    0.    0.    6.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    1.    0.    0.    0.    3.    1.    0.    0.    0.    0.    0.    0.    5.    4.  152.   23. 1750.    7.    2.   10.    0.    4.    1.    3.    4.   13.    0.    0.    1.    4.    2.    0.    0.]\n",
      " [   1.    0.    0.    0.   15.    0.    0.    3.    2.    1.    1.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    4.    0.    1.    0.    0.    1.    0.    2.   20.   10.    6.    4. 1901.    0.    2.    0.    0.    2.    0.    2.    3.    0.    0.    0.   13.    0.    0.    5.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    5.   44.    2.    1.    0.    1. 1673.    5.    0.  165.    3.    6.    0.   62.    4.    1.    2.   25.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    2.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    1.    0.    4.    3.    4.    2.    7.    2.    0. 1959.    0.    1.    1.    0.    3.    0.    0.    0.    0.    7.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.    1.    1.    0.    0.    0.    3.    0. 1978.    0.    1.    1.    0.    6.    0.    0.    0.    1.    0.    0.    0.]\n",
      " [   0.    3.    0.    0.    0.    0.    1.    1.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    1.    0.    9.  135.   16.    1.    1.    0.   92.    3.    0. 1575.   16.   55.    0.   75.    0.    0.    0.   13.    0.    0.    1.]\n",
      " [   1.    2.    0.    0.    0.    0.    0.    6.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.    0.    0.    0.    0.    0.    0.    0.    1.    0.    2.   59.    3.    1.    1.    0.    2.    0.    2.    5. 1882.    2.    0.   20.    2.    0.    0.    3.    0.    0.    1.]\n",
      " [   1.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.   14.    6.    0.    1.    0.    0.    0.    0.    5.    2. 1946.    0.   11.    0.    0.    0.    5.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    5.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    1.    1.    1.    0.    0.    0.    0.    0.    7.    0.    2.    9.    1.    7.    0.    4.    0.    0.    1.    0. 1957.    0.    0.    0.    0.    2.    0.    0.    0.]\n",
      " [   2.    5.    1.    0.    1.    0.    1.    5.    0.    0.    5.    0.    0.    2.    0.    0.    0.    0.    0.    0.    0.    0.    2.    0.    1.    0.    0.    0.    8.   40.   30.    4.    2.    2.   11.    0.    3.   26.   15.   19.    0. 1791.    2.    2.    4.   12.    3.    0.    1.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.    0.    0.    1.    0.    0.    0.    9. 1985.    0.    1.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    3.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0. 1991.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    1.    0.    0.    0.    0.    0.    0.    5.    2.    4.    0.   26.    1.    3. 1947.    4.    1.    0.    3.]\n",
      " [   1.    2.    0.    0.    1.    0.    1.    2.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   12.   19.    5.    0.    1.    1.   16.    1.    0.    6.    0.    2.    1.    7.    2.    0.    2. 1916.    0.    1.    0.]\n",
      " [   0.    0.    0.    0.    4.    0.    0.    1.    0.    0.    4.    0.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.    1.    0.    5.    1.    3.    1.    2.    1.    0.    2.    0.    1.    2.    0.    0.   26.    2.   12.    8.    6. 1912.    0.    1.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.    0. 1997.    0.]\n",
      " [  11.   10.    2.    0.   34.    0.  111.   22.   17.    6.    7.    0.    1.   13.    3.    5.    1.    0.   22.    0.    3.   10.  101.    2.   19.    4.    7.    7.    6.    4.    6.    4.    2.    2.    0.    1.    0.    0.    2.    0.    0.    7.    0.    0.    7.    2.    1.    1. 1537.]]\n"
     ]
    }
   ],
   "source": [
    "matrix = models.confusion_matrix(classifier, test_data, \"cuda\", mapping)\n",
    "plt.matshow(matrix)\n",
    "plt.show()\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=500, threshold=np.inf)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e088828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier.model.state_dict(), \"trained_models/mamba_v3/model.pt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908bb51",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 501/19473 [01:39<1:00:51,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 500. Epoch: 1. MLM loss: 5.3901. Patience: 3\n",
      "Average entropy: 5.3419. Correct predictions: 19043 / 1199798 (1.5872 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1001/19473 [03:15<59:20,  5.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000. Epoch: 1. MLM loss: 5.3505. Patience: 3\n",
      "Average entropy: 5.3026. Correct predictions: 21861 / 1200617 (1.8208 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1501/19473 [04:51<57:29,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1500. Epoch: 1. MLM loss: 5.3399. Patience: 3\n",
      "Average entropy: 5.2836. Correct predictions: 22487 / 1201967 (1.8709 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2001/19473 [06:27<55:36,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2000. Epoch: 1. MLM loss: 5.3304. Patience: 3\n",
      "Average entropy: 5.2656. Correct predictions: 23245 / 1199574 (1.9378 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2501/19473 [08:03<54:04,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2500. Epoch: 1. MLM loss: 5.3292. Patience: 3\n",
      "Average entropy: 5.2466. Correct predictions: 23012 / 1198153 (1.9206 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3001/19473 [09:38<52:26,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3000. Epoch: 1. MLM loss: 5.3246. Patience: 3\n",
      "Average entropy: 5.2293. Correct predictions: 23351 / 1201074 (1.9442 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3501/19473 [11:14<50:51,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3500. Epoch: 1. MLM loss: 5.3236. Patience: 3\n",
      "Average entropy: 5.2126. Correct predictions: 23440 / 1198886 (1.9551 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4001/19473 [12:49<49:10,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4000. Epoch: 1. MLM loss: 5.3234. Patience: 3\n",
      "Average entropy: 5.193. Correct predictions: 23265 / 1199027 (1.9403 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4501/19473 [14:24<47:32,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4500. Epoch: 1. MLM loss: 5.3220. Patience: 3\n",
      "Average entropy: 5.1718. Correct predictions: 23486 / 1201539 (1.9547 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 5001/19473 [16:00<45:56,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000. Epoch: 1. MLM loss: 5.3226. Patience: 3\n",
      "Average entropy: 5.1556. Correct predictions: 23301 / 1199560 (1.9425 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5501/19473 [17:35<44:17,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5500. Epoch: 1. MLM loss: 5.3202. Patience: 2\n",
      "Average entropy: 5.1567. Correct predictions: 23424 / 1197782 (1.9556 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 6001/19473 [19:10<42:53,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6000. Epoch: 1. MLM loss: 5.3199. Patience: 2\n",
      "Average entropy: 5.1306. Correct predictions: 23653 / 1197740 (1.9748 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6501/19473 [20:46<41:22,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6500. Epoch: 1. MLM loss: 5.3196. Patience: 2\n",
      "Average entropy: 5.0883. Correct predictions: 23173 / 1199484 (1.9319 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 7001/19473 [22:21<39:43,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7000. Epoch: 1. MLM loss: 5.3183. Patience: 2\n",
      "Average entropy: 5.0799. Correct predictions: 23748 / 1198899 (1.9808 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 7501/19473 [23:57<38:15,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7500. Epoch: 1. MLM loss: 5.3186. Patience: 2\n",
      "Average entropy: 5.0412. Correct predictions: 23215 / 1200595 (1.9336 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 8001/19473 [25:33<36:41,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8000. Epoch: 1. MLM loss: 5.3179. Patience: 1\n",
      "Average entropy: 5.025. Correct predictions: 23755 / 1200409 (1.9789 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 8501/19473 [27:09<35:03,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8500. Epoch: 1. MLM loss: 5.3170. Patience: 1\n",
      "Average entropy: 5.0311. Correct predictions: 23982 / 1199347 (1.9996 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 9001/19473 [28:45<33:19,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9000. Epoch: 1. MLM loss: 5.3152. Patience: 1\n",
      "Average entropy: 5.0027. Correct predictions: 23926 / 1198835 (1.9958 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 9499/19473 [30:20<31:51,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9500. Epoch: 1. MLM loss: 5.3159. Patience: 1\n",
      "Average entropy: 5.0208. Correct predictions: 24436 / 1201906 (2.0331 %).\n",
      "Overfitting; stopping early.\n",
      "Fine-tuning:\n",
      "Number of parameters: 913_458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/9196 [00:24<19:43:54,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.33184, 0.034708]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1002/9196 [03:54<11:05:21,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.77585, 0.58068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [07:24<9:43:27,  4.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.79995, 0.63091]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [14:00<7:01:19,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.81148, 0.67156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6002/9196 [20:37<4:19:59,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.85178, 0.70016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8002/9196 [27:15<1:37:01,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.84238, 0.70859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [30:59<00:00,  4.95it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 T loss: 3.47714. V loss: 2.84366. F1: [0.84651, 0.71103]. P: [0.84412, 0.71645] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/9196 [00:23<18:48:38,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.84302, 0.70841]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1002/9196 [03:52<11:06:08,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.85857, 0.7309]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2002/9196 [07:22<9:45:15,  4.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.84688, 0.72656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4002/9196 [13:59<7:05:50,  4.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.86536, 0.73518]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6002/9196 [20:40<4:23:27,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.86108, 0.73801]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8002/9196 [27:20<1:37:50,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.86943, 0.74343]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [31:04<00:00,  4.93it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 T loss: 2.64411. V loss: 2.56356. F1: [0.86215, 0.74755]. P: [0.86454, 0.75337] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/9196 [00:23<18:57:09,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.86557, 0.74995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1002/9196 [03:53<11:14:41,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.87025, 0.7522]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1065/9196 [04:06<31:18,  4.33it/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# classifier.model.freeze_base()\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFine-tuning:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m model = \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTransformer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\n\u001b[32m     74\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m matrix = models.confusion_matrix(model, test_data, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, mapping)\n\u001b[32m     76\u001b[39m plt.matshow(matrix)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mbenchmark\u001b[39m\u001b[34m(classifier, name, max_epochs, loss_fn, evaluation_interval, learning_rate)\u001b[39m\n\u001b[32m     54\u001b[39m     optimizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     55\u001b[39m a = time()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m losses, f1, validation_losses = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_n_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msupervised\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_interval\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m b = time()\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(b\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39ma)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/maitrise/stelaro/stelaro/models/__init__.py:793\u001b[39m, in \u001b[36mClassifier.train\u001b[39m\u001b[34m(self, train_loader, validate_loader, optimizer, max_n_epochs, patience, loss_function, loss_function_type, evaluation_interval)\u001b[39m\n\u001b[32m    791\u001b[39m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m    792\u001b[39m optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m losses[-\u001b[32m1\u001b[39m] += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m progress \u001b[38;5;129;01mand\u001b[39;00m progress % evaluation_interval == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m progress \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m1\u001b[39m, evaluation_interval // \u001b[32m2\u001b[39m):\n\u001b[32m    795\u001b[39m     ps = estimate_precision(\u001b[38;5;28mself\u001b[39m, validate_loader, \u001b[38;5;28mself\u001b[39m.device, \u001b[38;5;28mself\u001b[39m.mapping)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch import arange\n",
    "from torch.nn import (Module, Linear, Embedding, TransformerEncoderLayer,\n",
    "                      TransformerEncoder)\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "\n",
    "class T(Module):\n",
    "    def __init__(self, N, M):\n",
    "        super(T, self).__init__()\n",
    "        embed_dim = 128\n",
    "        vocab_size = 256\n",
    "        self.token_embedding = Embedding(vocab_size + 1, embed_dim)\n",
    "        self.position_embedding = Embedding(N, embed_dim)\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=4,\n",
    "            dim_feedforward=embed_dim * 4,\n",
    "            dropout=0.1,\n",
    "            activation='relu',\n",
    "            batch_first=True  # makes input/output shape [B, L, D]\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=4)\n",
    "        self.mlm_head = nn.Linear(embed_dim, vocab_size + 1)\n",
    "        self.classifier = Linear(embed_dim, M)\n",
    "\n",
    "    def forward(self, x, mlm=None):\n",
    "        batch_size, seq_len = x.size()\n",
    "        positions = arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "        x = self.token_embedding(x) + self.position_embedding(positions)  # [B, L, D]\n",
    "        h = self.transformer_encoder(x)  # [B, L, D]\n",
    "        if mlm is not None:\n",
    "            logits = self.mlm_head(h)  # [B, L, vocab_size + 1]\n",
    "            return logits\n",
    "        else:\n",
    "            h = h.mean(dim=1)  # [B, D] - average pooling\n",
    "            logits = self.classifier(h)  # [B, num_classes]\n",
    "            return logits\n",
    "\n",
    "\n",
    "classifier = models.Classifier(\n",
    "    LENGTH // 4,\n",
    "    mapping,\n",
    "    \"cuda\",\n",
    "    T,\n",
    "    format.to_tetramers,\n",
    "    True\n",
    ")\n",
    "\n",
    "print(\"Pretraining:\")\n",
    "optimizer = AdamW(classifier.get_parameters(), lr=0.001)\n",
    "pretraining_data = DataLoader(\n",
    "    models.SyntheticTetramerDataset(PROCESSED_PRETRAINING_DATA, labels=False),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "classifier.pretrain(\n",
    "    pretraining_data,\n",
    "    optimizer,\n",
    "    20_000,\n",
    "    256,\n",
    "    patience=3,\n",
    "    mlm_probability=0.05\n",
    ")\n",
    "# classifier.model.freeze_base()\n",
    "\n",
    "print(\"Fine-tuning:\")\n",
    "model = benchmark(\n",
    "    classifier,\n",
    "    \"Transformer\",\n",
    "    max_epochs=10,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    evaluation_interval=2000,\n",
    "    learning_rate=0.0001\n",
    ")\n",
    "matrix = models.confusion_matrix(model, test_data, \"cuda\", mapping)\n",
    "plt.matshow(matrix)\n",
    "plt.show()\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=500, threshold=np.inf)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dddde8",
   "metadata": {},
   "source": [
    "# Mamba-Transformer Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd4578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/maitrise/stelaro/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 500/19473 [02:46<1:42:58,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 500. Epoch: 1. MLM loss: 5.3635. Patience: 3\n",
      "Average entropy: 5.315. Correct predictions: 121831 / 7199276 (1.6923 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1000/19473 [05:30<1:41:07,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000. Epoch: 1. MLM loss: 5.2760. Patience: 3\n",
      "Average entropy: 5.2028. Correct predictions: 160857 / 7201461 (2.2337 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1500/19473 [08:14<1:37:57,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1500. Epoch: 1. MLM loss: 5.2462. Patience: 3\n",
      "Average entropy: 5.1724. Correct predictions: 171742 / 7199129 (2.3856 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2000/19473 [10:57<1:35:34,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2000. Epoch: 1. MLM loss: 5.2263. Patience: 3\n",
      "Average entropy: 5.1503. Correct predictions: 179562 / 7197665 (2.4947 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2500/19473 [13:41<1:32:35,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2500. Epoch: 1. MLM loss: 5.1971. Patience: 3\n",
      "Average entropy: 5.1374. Correct predictions: 188240 / 7199173 (2.6147 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3000/19473 [16:25<1:29:59,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3000. Epoch: 1. MLM loss: 5.1775. Patience: 3\n",
      "Average entropy: 5.1277. Correct predictions: 191270 / 7201211 (2.6561 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3500/19473 [19:08<1:27:11,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3500. Epoch: 1. MLM loss: 5.1666. Patience: 3\n",
      "Average entropy: 5.1212. Correct predictions: 195376 / 7201845 (2.7129 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 4000/19473 [21:52<1:24:42,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4000. Epoch: 1. MLM loss: 5.1622. Patience: 3\n",
      "Average entropy: 5.115. Correct predictions: 198943 / 7201293 (2.7626 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4500/19473 [24:36<1:22:01,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4500. Epoch: 1. MLM loss: 5.1564. Patience: 3\n",
      "Average entropy: 5.1126. Correct predictions: 201937 / 7199942 (2.8047 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 5000/19473 [27:21<1:19:11,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000. Epoch: 1. MLM loss: 5.1496. Patience: 3\n",
      "Average entropy: 5.1105. Correct predictions: 204343 / 7199795 (2.8382 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5500/19473 [30:05<1:16:38,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5500. Epoch: 1. MLM loss: 5.1456. Patience: 3\n",
      "Average entropy: 5.1056. Correct predictions: 205728 / 7201354 (2.8568 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 6000/19473 [32:49<1:13:31,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6000. Epoch: 1. MLM loss: 5.1420. Patience: 3\n",
      "Average entropy: 5.103. Correct predictions: 208736 / 7198751 (2.8996 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6500/19473 [35:32<1:10:45,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6500. Epoch: 1. MLM loss: 5.1394. Patience: 3\n",
      "Average entropy: 5.0997. Correct predictions: 208250 / 7198792 (2.8928 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 7000/19473 [38:16<1:08:01,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7000. Epoch: 1. MLM loss: 5.1366. Patience: 3\n",
      "Average entropy: 5.0989. Correct predictions: 210919 / 7201998 (2.9286 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 7500/19473 [40:59<1:05:20,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7500. Epoch: 1. MLM loss: 5.1297. Patience: 3\n",
      "Average entropy: 5.0893. Correct predictions: 214843 / 7201996 (2.9831 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 8000/19473 [43:43<1:02:46,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8000. Epoch: 1. MLM loss: 5.1252. Patience: 3\n",
      "Average entropy: 5.084. Correct predictions: 216442 / 7200073 (3.0061 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 8500/19473 [46:27<1:00:03,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8500. Epoch: 1. MLM loss: 5.1218. Patience: 3\n",
      "Average entropy: 5.0793. Correct predictions: 217043 / 7199758 (3.0146 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 9000/19473 [49:11<57:06,  3.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9000. Epoch: 1. MLM loss: 5.1151. Patience: 3\n",
      "Average entropy: 5.0726. Correct predictions: 220392 / 7200516 (3.0608 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 9500/19473 [51:56<56:40,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9500. Epoch: 1. MLM loss: 5.1126. Patience: 3\n",
      "Average entropy: 5.069. Correct predictions: 219227 / 7200343 (3.0447 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 10000/19473 [54:40<51:51,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000. Epoch: 1. MLM loss: 5.1119. Patience: 3\n",
      "Average entropy: 5.0673. Correct predictions: 218593 / 7200251 (3.0359 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 10500/19473 [57:24<49:02,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10500. Epoch: 1. MLM loss: 5.1072. Patience: 3\n",
      "Average entropy: 5.06. Correct predictions: 221005 / 7199859 (3.0696 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 11000/19473 [1:00:08<46:22,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11000. Epoch: 1. MLM loss: 5.1051. Patience: 3\n",
      "Average entropy: 5.0583. Correct predictions: 224202 / 7196697 (3.1153 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 11500/19473 [1:02:52<43:28,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11500. Epoch: 1. MLM loss: 5.1018. Patience: 3\n",
      "Average entropy: 5.0532. Correct predictions: 225805 / 7200530 (3.1359 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 12000/19473 [1:05:35<40:37,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12000. Epoch: 1. MLM loss: 5.0990. Patience: 3\n",
      "Average entropy: 5.0498. Correct predictions: 227338 / 7202099 (3.1566 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 12500/19473 [1:08:19<37:57,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12500. Epoch: 1. MLM loss: 5.0992. Patience: 3\n",
      "Average entropy: 5.0473. Correct predictions: 226709 / 7201498 (3.1481 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 13000/19473 [1:11:02<35:14,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13000. Epoch: 1. MLM loss: 5.0981. Patience: 2\n",
      "Average entropy: 5.0473. Correct predictions: 226796 / 7204596 (3.1479 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 13500/19473 [1:13:45<32:27,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13500. Epoch: 1. MLM loss: 5.0944. Patience: 2\n",
      "Average entropy: 5.0437. Correct predictions: 227208 / 7199732 (3.1558 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 14000/19473 [1:16:28<29:41,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14000. Epoch: 1. MLM loss: 5.0957. Patience: 2\n",
      "Average entropy: 5.0452. Correct predictions: 228300 / 7195505 (3.1728 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 14500/19473 [1:19:11<27:04,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14500. Epoch: 1. MLM loss: 5.0926. Patience: 1\n",
      "Average entropy: 5.0449. Correct predictions: 229420 / 7195075 (3.1886 %).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 14999/19473 [1:21:54<24:24,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15000. Epoch: 1. MLM loss: 5.0936. Patience: 1\n",
      "Average entropy: 5.042. Correct predictions: 228743 / 7197108 (3.1783 %).\n",
      "Overfitting; stopping early.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 14999/19473 [1:21:54<24:26,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning:\n",
      "Number of parameters: 1_380_658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<3:11:41,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45056 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<47:43:04, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.42241, 0.049277]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [05:58<44:25,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 44416 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [06:29<21:30:43,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.88077, 0.73259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [11:57<38:47,  3.09it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45184 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [12:28<18:51:49,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.92094, 0.7857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [23:13<27:59,  3.09it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45056 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [23:44<13:37:41,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.90554, 0.79134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [34:29<17:11,  3.10it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45312 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [35:00<8:23:17,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.91446, 0.82309]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [45:46<06:26,  3.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45184 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [46:17<3:08:16,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93206, 0.83903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [52:43<00:00,  2.91it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 10752 data points.\n",
      "1/10 T loss: 2.10920. V loss: 1.64894. F1: [0.93616, 0.83679]. P: [0.93671, 0.83969] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<4:58:45,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45312 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<48:22:38, 18.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.9389, 0.84388]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [08:09<1:02:12,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45312 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [08:40<22:00:32,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.92117, 0.83738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [16:17<54:50,  2.19it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45184 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [16:48<19:10:30,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94153, 0.85287]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [32:00<39:21,  2.20it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45440 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [32:31<13:49:39,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94455, 0.86431]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [47:44<24:19,  2.19it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45184 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [48:15<8:30:18,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94252, 0.86594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [1:03:28<09:03,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45312 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [1:03:59<3:10:31,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94374, 0.87343]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [1:13:04<00:00,  2.10it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 4608 data points.\n",
      "2/10 T loss: 1.40372. V loss: 1.29262. F1: [0.94564, 0.86883]. P: [0.93544, 0.8666] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<3:42:40,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45312 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<47:50:16, 18.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.93347, 0.86915]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9196 [08:07<1:02:11,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45056 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1001/9196 [08:38<21:46:39,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94521, 0.87296]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9196 [16:13<54:24,  2.20it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45568 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9196 [16:44<19:07:55,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94917, 0.87066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4000/9196 [31:54<39:34,  2.19it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45184 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 4001/9196 [32:25<13:49:47,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95564, 0.88122]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6000/9196 [47:36<24:23,  2.18it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45184 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6001/9196 [48:07<8:30:12,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95554, 0.87495]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8000/9196 [1:03:21<09:10,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45056 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9196 [1:03:52<3:10:34,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.94866, 0.8824]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9196/9196 [1:12:59<00:00,  2.10it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 4608 data points.\n",
      "3/10 T loss: 1.18623. V loss: 1.16322. F1: [0.95463, 0.88472]. P: [0.95337, 0.8837] Patience: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9196 [00:01<3:40:22,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halting evaluation after 45184 data points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9196 [00:32<47:54:38, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [0.95628, 0.88725]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 426/9196 [03:47<1:17:55,  1.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m     97\u001b[39m classifier.pretrain(\n\u001b[32m     98\u001b[39m     pretraining_data,\n\u001b[32m     99\u001b[39m     optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m     mlm_probability=\u001b[32m0.3\u001b[39m\n\u001b[32m    104\u001b[39m )\n\u001b[32m    106\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFine-tuning:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m model = \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMAMBA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\n\u001b[32m    114\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m matrix = models.confusion_matrix(model, test_data, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, mapping)\n\u001b[32m    116\u001b[39m plt.matshow(matrix)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mbenchmark\u001b[39m\u001b[34m(classifier, name, max_epochs, loss_fn, evaluation_interval, learning_rate)\u001b[39m\n\u001b[32m     54\u001b[39m     optimizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     55\u001b[39m a = time()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m losses, f1, validation_losses = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_n_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_function_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msupervised\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_interval\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m b = time()\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(b\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39ma)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/maitrise/stelaro/stelaro/models/__init__.py:793\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(self, train_loader, validate_loader, optimizer, max_n_epochs, patience, loss_function, loss_function_type, evaluation_interval)\u001b[39m\n\u001b[32m    791\u001b[39m progress = \u001b[32m0\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m._compute_loss(\n\u001b[32m    794\u001b[39m         x_batch, y_batch, loss_function_type, loss_function\n\u001b[32m    795\u001b[39m     )\n\u001b[32m    796\u001b[39m     optimizer.zero_grad()\n\u001b[32m    797\u001b[39m     loss.backward()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch import arange\n",
    "from torch.optim import Adam, AdamW\n",
    "import torch\n",
    "from torch.nn import Embedding, TransformerEncoderLayer, TransformerEncoder\n",
    "from mamba_ssm import Mamba\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_state, d_conv, expand):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.mamba = Mamba(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pre-norm + residual connection\n",
    "        return x + self.mamba(self.norm(x))\n",
    "\n",
    "\n",
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        N: int,\n",
    "        num_classes: int,\n",
    "        n_mamba_layers: int = 4,\n",
    "        n_transformer_layers: int = 4,\n",
    "        vocab_size: int = 256,\n",
    "        d_model: int = 128,\n",
    "        d_state: int = 16,\n",
    "        d_conv: int = 4,\n",
    "        expand: int = 2,\n",
    "        pooling = \"mean\",\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, d_model)\n",
    "        self.mamba_layers = nn.ModuleList([\n",
    "            MambaBlock(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand)\n",
    "            for _ in range(n_mamba_layers)\n",
    "        ])\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=4,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=0.1,\n",
    "            activation='relu',\n",
    "            batch_first=True  # makes input/output shape [B, L, D]\n",
    "        )\n",
    "        self.transformer_1 = TransformerEncoder(encoder_layer, num_layers=n_transformer_layers)\n",
    "        self.position_embedding = Embedding(N, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        self.classifying_head = nn.Linear(d_model, num_classes)\n",
    "        self.pooling = pooling\n",
    "        self.mlm_head = nn.Linear(d_model, vocab_size + 1)\n",
    "\n",
    "    def forward(self, x: torch.LongTensor, mlm=None) -> torch.Tensor:\n",
    "        h = self.embedding(x)\n",
    "        for block in self.mamba_layers:\n",
    "            h = block(h)   # [B, L, d_model]\n",
    "        h = self.norm(h)\n",
    "        batch_size, seq_len, _ = h.size()\n",
    "        positions = arange(seq_len, device=h.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "        h = h + self.position_embedding(positions)  # [B, L, d_model]\n",
    "        h = self.transformer_1(h)\n",
    "        if mlm is not None:\n",
    "            logits = self.mlm_head(h)  # [B, L, vocab_size + 1]\n",
    "            return logits\n",
    "        else:\n",
    "            pooled = h.mean(dim=1)  # [B, d_model]\n",
    "            pooled = self.dropout(pooled)\n",
    "            logits = self.classifying_head(pooled)  # [B, num_classes]\n",
    "            return logits\n",
    "\n",
    "\n",
    "classifier = models.Classifier(\n",
    "    LENGTH // 4,\n",
    "    mapping,\n",
    "    \"cuda\",\n",
    "    MambaSequenceClassifier,\n",
    "    format.to_tetramers,\n",
    "    True\n",
    ")\n",
    "\n",
    "print(\"Pretraining:\")\n",
    "optimizer = AdamW(classifier.get_parameters(), lr=0.001)\n",
    "pretraining_data = DataLoader(\n",
    "    models.SyntheticTetramerDataset(PROCESSED_PRETRAINING_DATA, labels=False),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "classifier.pretrain(\n",
    "    pretraining_data,\n",
    "    optimizer,\n",
    "    20_000,\n",
    "    256,\n",
    "    patience=3,\n",
    "    mlm_probability=0.3\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning:\")\n",
    "model = benchmark(\n",
    "    classifier,\n",
    "    \"MAMBA\",\n",
    "    max_epochs=10,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    evaluation_interval=2000,\n",
    "    learning_rate=0.0001\n",
    ")\n",
    "matrix = models.confusion_matrix(model, test_data, \"cuda\", mapping)\n",
    "plt.matshow(matrix)\n",
    "plt.show()\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=500, threshold=np.inf)\n",
    "print(matrix)\n",
    "\n",
    "\n",
    "# 30 %, 1 mamba, 4 layer transformer, 128 embedding\n",
    "# Step: 17000. Epoch: 1. MLM loss: 5.1003. Patience: 1\n",
    "# Average entropy: 5.0083. Correct predictions: 225983 / 7201924 (3.1378 %).\n",
    "# 1/10 T loss: 2.23986. V loss: 1.75391. F1: [0.92957, 0.82463]. P: [0.94515, 0.83342] Patience: 3\n",
    "# 2/10 T loss: 1.51715. V loss: 1.43216. F1: [0.93843, 0.85599]. P: [0.93894, 0.85787] Patience: 3\n",
    "# 3/10 T loss: 1.29859. V loss: 1.37382. F1: [0.94612, 0.86428]. P: [0.94224, 0.86721] Patience: 3\n",
    "\n",
    "# 30 %, 4 mamba, 4 layer transformer, 128 embedding\n",
    "# Step: 15000. Epoch: 1. MLM loss: 5.0936. Patience: 1\n",
    "# Average entropy: 5.042. Correct predictions: 228743 / 7197108 (3.1783 %).\n",
    "# 1/10 T loss: 2.10920. V loss: 1.64894. F1: [0.93616, 0.83679]. P: [0.93671, 0.83969] Patience: 3\n",
    "# 2/10 T loss: 1.40372. V loss: 1.29262. F1: [0.94564, 0.86883]. P: [0.93544, 0.8666] Patience: 3\n",
    "# 3/10 T loss: 1.18623. V loss: 1.16322. F1: [0.95463, 0.88472]. P: [0.95337, 0.8837] Patience: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.95535, 0.88538]\n",
      "Precision: [0.95351, 0.88893]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "result = models.evaluate(classifier, test_data, \"cuda\", mapping)\n",
    "rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "print(f\"F1: {rounded_result}\")\n",
    "result = models.evaluate_precision(classifier, test_data, \"cuda\", mapping)\n",
    "rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "print(f\"Precision: {rounded_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae55a64d",
   "metadata": {},
   "source": [
    "# Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39735249",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTAX_TRAIN = BERTAX_DIRECTORY + \"train/\"\n",
    "BERTAX_VALIDATION = BERTAX_DIRECTORY + \"validation/\"\n",
    "BERTAX_TEST = BERTAX_DIRECTORY + \"test/\"\n",
    "\n",
    "from time import time\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "from stelaro import models\n",
    "from stelaro.models import autoencoder, feedforward, transformer\n",
    "\n",
    "LENGTH = 1500\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "with open(BERTAX_DIRECTORY + \"statistics/map.json\", \"r\") as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "\n",
    "train_data = DataLoader(\n",
    "    models.SyntheticMultiLevelTetramerDataset(\n",
    "        BERTAX_TRAIN,\n",
    "        mapping,\n",
    "        (),\n",
    "        1,\n",
    "        balance = True,\n",
    "        other_factor = 0\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "validation_data = DataLoader(\n",
    "    models.SyntheticMultiLevelTetramerDataset(\n",
    "        BERTAX_VALIDATION,\n",
    "        mapping,\n",
    "        (),\n",
    "        1,\n",
    "        balance = False,\n",
    "        other_factor = 0\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_data = DataLoader(\n",
    "    models.SyntheticMultiLevelTetramerDataset(\n",
    "        BERTAX_TEST,\n",
    "        mapping,\n",
    "        (),\n",
    "        1,\n",
    "        balance = False,\n",
    "        other_factor = 0\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "mapping = train_data.dataset.mapping\n",
    "\n",
    "\n",
    "def benchmark(\n",
    "        classifier: models.Classifier,\n",
    "        name: str,\n",
    "        max_epochs: int = 20,\n",
    "        learning_rate: float = 0.001\n",
    "    ):\n",
    "    parameters = classifier.get_parameters()\n",
    "    if parameters:\n",
    "        optimizer = Adam(classifier.get_parameters(), lr=learning_rate)\n",
    "        total_params = sum(param.numel() for param in parameters)\n",
    "        print(f\"Number of parameters: {total_params:_}\")\n",
    "    else:\n",
    "        optimizer = None\n",
    "    a = time()\n",
    "    losses, f1, validation_losses = classifier.train(\n",
    "        train_data,\n",
    "        validation_data,\n",
    "        optimizer,\n",
    "        max_n_epochs=max_epochs,\n",
    "        patience=3,\n",
    "        loss_function=nn.CrossEntropyLoss(),\n",
    "        loss_function_type=\"supervised\",\n",
    "        evaluation_interval=5000,\n",
    "    )\n",
    "    b = time()\n",
    "    print(f\"Training took {(b - a):.3f} s.\")\n",
    "    if losses:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        x = list(range(len(losses)))\n",
    "        ax[0].plot(x, losses, label=\"Training\")\n",
    "        ax[0].plot(x, validation_losses, label=\"Validation\")\n",
    "        ax[0].set(xlabel='Epochs', ylabel='Loss')\n",
    "        ax[0].set_title(\"Normalized Loss Against Epochs\")\n",
    "        ax[0].legend()\n",
    "        ax[1].set(xlabel='Epochs', ylabel=\"f1\")\n",
    "        ax[1].set_title(\"F1 Score\")\n",
    "        r = 0\n",
    "        for f in f1:\n",
    "            ax[1].plot(x, f, label=f'Rank {r}')\n",
    "            r += 1\n",
    "        ax[1].legend()\n",
    "        fig.suptitle(f\"Classification Training for {name}\")\n",
    "        plt.show()\n",
    "    result = models.evaluate(classifier, test_data, \"cuda\", mapping)\n",
    "    rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "    print(f\"Test F1 score: {rounded_result}\")\n",
    "\n",
    "    result = models.evaluate_precision(classifier, test_data, \"cuda\", mapping)\n",
    "    rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "    print(f\"Test precision score: {rounded_result}\")\n",
    "\n",
    "    return classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
