{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ae27f1",
   "metadata": {},
   "source": [
    "# Large Dataset Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54f5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from stelaro.data import synthetic\n",
    "\n",
    "DATA_DIRECTORY = \"../data/\"\n",
    "SUMMARY_DIRECTORY = DATA_DIRECTORY + \"ncbi_genome_summaries/\"\n",
    "NCBI_TAXONOMY_DIRECTORY = DATA_DIRECTORY + \"ncbi_taxonomy/\"\n",
    "DATASET_V1_DIRECTORY = DATA_DIRECTORY + \"version_1/\"\n",
    "DATASET_V1_COMPRESSED_DIRECTORY = DATASET_V1_DIRECTORY + \"compressed/\"\n",
    "\n",
    "\n",
    "def mkdir(path: str) -> None:\n",
    "    \"\"\"Create a directory if it does not exist.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "mkdir(DATA_DIRECTORY)\n",
    "mkdir(DATASET_V1_DIRECTORY)\n",
    "mkdir(DATASET_V1_COMPRESSED_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b9728e",
   "metadata": {},
   "source": [
    "## 1. Compress The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426a559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [06:14<00:00, 13.86s/it]\n",
      "100%|██████████| 27/27 [05:45<00:00, 12.81s/it]\n",
      "100%|██████████| 27/27 [41:05<00:00, 91.32s/it] \n"
     ]
    }
   ],
   "source": [
    "LENGTH = 1500\n",
    "with open(\"../datasets/version_1_splits/map.json\", \"r\") as f:\n",
    "    index_to_taxonomic_label = json.load(f)\n",
    "\n",
    "for dataset_name in (\"validate\", \"test\", \"train\"):\n",
    "    with open(f\"../datasets/version_1_splits/{dataset_name}.json\", \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "    index_to_n_passes = {}\n",
    "    directory = DATASET_V1_COMPRESSED_DIRECTORY + dataset_name + \"/\"\n",
    "    mkdir(directory)\n",
    "    synthetic.compress_dataset(\n",
    "        dataset,\n",
    "        index_to_taxonomic_label,\n",
    "        \"../data/version_1/genomes/\",\n",
    "        LENGTH,\n",
    "        directory\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f6fd9",
   "metadata": {},
   "source": [
    "## 2. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80aac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = synthetic.get_n_reads_in_compressed_dataset(\n",
    "    DATASET_V1_COMPRESSED_DIRECTORY + \"train/\",\n",
    ")\n",
    "ids = synthetic.get_random_identifiers(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa734fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5398 12157  2987  6817  6141   994 13232 13711  2553  8935  3209  3800\n",
      " 12401  5645  3268  1090  8832  6483  9312 12444 11964 13768 16315 14968\n",
      "  3098   407    71]\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "from numpy import bincount\n",
    "x, y = synthetic.sample_compressed_dataset(\n",
    "    DATASET_V1_COMPRESSED_DIRECTORY + \"train/\",\n",
    "    200_000,\n",
    "    1500,\n",
    "    ids,\n",
    "    400000\n",
    ")\n",
    "print(bincount(y))\n",
    "print(sum(bincount(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a206af78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Viruses', 'Monodnaviria']\n",
      "5158834\n"
     ]
    }
   ],
   "source": [
    "with open(f\"../datasets/version_1_splits/train.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "\n",
    "taxon = dataset[-1]\n",
    "print(taxon[0])\n",
    "references = []\n",
    "for element in taxon[1]:\n",
    "    genus, ref = element\n",
    "    references += ref\n",
    "print(synthetic.evaluate_n_nucleotides(references))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc08ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 375)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.load(DATASET_V1_COMPRESSED_DIRECTORY + \"train/0_x.npy\")\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950054ab",
   "metadata": {},
   "source": [
    "## 3. Train Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33f08b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8781862\n"
     ]
    }
   ],
   "source": [
    "from stelaro import models\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from stelaro.models import feedforward, autoencoder, transformer\n",
    "from time import time\n",
    "\n",
    "LENGTH = 1500\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data = DataLoader(\n",
    "    synthetic.CompressedReadDataset(\n",
    "        \"../data/version_1/compressed/train/\", 10_000\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "validate_data = DataLoader(\n",
    "    synthetic.SyntheticReadDataset(\n",
    "        \"../data/version_1/compressed/validate/\", 10_000, LENGTH\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "test_data = DataLoader(\n",
    "    synthetic.SyntheticReadDataset(\n",
    "        \"../data/version_1/compressed/test/\", 10_000, LENGTH\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "with open(\"../data/version_1/static/train/map.json\", \"r\") as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "\n",
    "def benchmark(classifier: models.BaseClassifier, name: str, n_max_reads=30_000):\n",
    "    parameters = classifier.get_parameters()\n",
    "    if parameters:\n",
    "        optimizer = Adam(classifier.get_parameters(), lr=0.001)\n",
    "        total_params = sum(param.numel() for param in parameters)\n",
    "        print(f\"Number of parameters: {total_params:_}\")\n",
    "    else:\n",
    "        optimizer = None\n",
    "    a = time()\n",
    "    losses, f1 = classifier.train_large_dataset(\n",
    "        train_data,\n",
    "        validate_data,\n",
    "        optimizer,\n",
    "        evaluation_interval=10_000,\n",
    "        n_max_reads=n_max_reads,\n",
    "        patience=3,\n",
    "    )\n",
    "    b = time()\n",
    "    print(f\"Training took {(b - a):.3f} s.\")\n",
    "    if losses:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        x = list(range(len(losses)))\n",
    "        ax[0].plot(x, losses, label=\"losses\")\n",
    "        ax[0].set(xlabel='Epochs', ylabel='Loss')\n",
    "        ax[0].set_title(\"Loss\")\n",
    "        ax[1].set(xlabel='Epochs', ylabel=\"f1\")\n",
    "        ax[1].set_title(\"F1 Score\")\n",
    "        r = 0\n",
    "        for f in f1:\n",
    "            ax[1].plot(x, f, label=f'Rank {r}')\n",
    "            r += 1\n",
    "        ax[1].legend()\n",
    "        fig.suptitle(f\"Classification Training for {name}\")\n",
    "        plt.show()\n",
    "    result = models.evaluate(classifier, test_data, \"cuda\", mapping)\n",
    "    rounded_result = [float(f\"{r:.5}\") for r in result]\n",
    "    print(f\"Test results: {rounded_result}\")\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89076ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 234/68609 [00:33<2:43:06,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 33.499 s.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRandom Classifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 72\u001b[0m, in \u001b[0;36mbenchmark\u001b[1;34m(classifier, name, n_max_reads)\u001b[0m\n\u001b[0;32m     70\u001b[0m     fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Training for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 72\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m rounded_result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrounded_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\maitrise\\stelaro\\stelaro\\models\\__init__.py:257\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(classifier, loader, device, mapping)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m    256\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mtype(float32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 257\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m \u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Swap channels and sequence.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(x_batch)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    models.RandomClassifier(),\n",
    "    \"Random Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8fbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
