"""
    Transform reference genomes files into synthetic read files.

    - Author: Vincent Therrien (therrien.vincent.2@courrier.uqam.ca)
    - Affiliation: Département d'informatique, UQÀM
    - File creation date: June 2025
    - License: MIT
"""

import numpy as np
from random import choices, randint
from tqdm import tqdm
import json
from . import read_genome


NUCLEOTIDE_TO_ONEHOT = {
    'A': 0b1000,
    'C': 0b0100,
    'G': 0b0010,
    'T': 0b0001,
    'N': 0b0000,
}
ONEHOT_TO_NUCLEOTIDE = {v: k for k, v in NUCLEOTIDE_TO_ONEHOT.items()}
SEQUENCE_TO_SAMPLE_MINIMUM_LENGTH_RATIO = 1.5
MAXIMUM_UNDEFINED_FRACTION = 0.05


def find_index_from_label(
        index_to_taxonomic_label: dict,
        label: tuple[str]
        ) -> int:
    """Determine the index of a particular taxonomic label."""
    for i in index_to_taxonomic_label:
        if index_to_taxonomic_label[i] == label:
            return i
    raise RuntimeError(f"Label {label} has no index.")


def sample_read(
        genome: list[str],
        n_reads: int,
        length: int,
        ) -> list[int]:
    """Generate synthetic reads from a genome."""
    samples = []
    minimum = SEQUENCE_TO_SAMPLE_MINIMUM_LENGTH_RATIO * length
    indices = [i for i in range(len(genome)) if len(genome[i][1]) > minimum]
    if len(indices) < 1:
        raise RuntimeError(f"Reads are too short.")
    sequence_lengths = []
    for i in indices:
        sequence_lengths.append(len(genome[i][1]))
    for _ in range(n_reads):
        for _ in range(5):
            selection = choices(indices, weights=sequence_lengths, k=1)[0]
            sequence = genome[selection][1]
            cursor = randint(0, len(sequence) - length)
            sequence = sequence[cursor:cursor + length]
            fraction = sequence.count('N') / length
            if fraction < MAXIMUM_UNDEFINED_FRACTION:
                encoding = [NUCLEOTIDE_TO_ONEHOT[s] for s in sequence]
                samples.append(encoding)
                break
        else:
            raise RuntimeError(f"Could not generate an acceptable read.")
    return samples


def decode(sequence: list[int]) -> str:
    characters = [ONEHOT_TO_NUCLEOTIDE[s] for s in sequence]
    return "".join(characters)



def write(
        dataset: list,
        index_to_taxonomic_label: dict,
        index_to_n_passes: dict,
        reference_genome_directory: str,
        read_length: int,
        dst: str,
        ) -> int:
    """Write a synthetic read dataset in a Numpy array.

    The `x` array contains one-hot encoded reads. The `y` arrays contains an
    identifier for the origin of the corresponding read.

    Args:
        dataset: Maps bins to reference genomes. Generated by
            `ncbi.bin_genomes` or `Taxonomy.bin_genomes`.
        index_to_taxonomic_label: Maps bins to an integer identifier.
        index_to_n_passes: Number of times that the genomes in each bin must be
            sampled.
        reference_genome_directory: Path of the directory that contains the
            installed reference genomes.
        read_length: Length of the synthetic reads to sample.
        dst: Path of the file in which to write the result.

    Returns: Number of sampled synthetic reads.
    """
    # Preparation
    assert reference_genome_directory.endswith("/")
    n_reads = 0
    for label, genome_list in dataset:
        index = find_index_from_label(index_to_taxonomic_label, label)
        n_passes = index_to_n_passes[index]
        for _, sub_genome_list in genome_list:
            n_reads += len(sub_genome_list) * n_passes
    size = n_reads * read_length
    print(f"Estimated file size: {size / 1000000} MB.")
    print(f"Average number of reads per bin: {n_reads / len(dataset):.2f}")
    # Create the datasets.
    i = 0
    x = np.zeros((n_reads, read_length), dtype=np.int8)
    y = np.zeros(n_reads, dtype=np.int8)
    with tqdm(total=n_reads) as progress_bar:
        for label, genome_list in dataset:
            index = find_index_from_label(index_to_taxonomic_label, label)
            n_passes = index_to_n_passes[index]
            for _, sub_genome_list in genome_list:
                for genome_id in sub_genome_list:
                    filename = f"{reference_genome_directory}{genome_id}.fna"
                    genome = read_genome(filename)
                    try:
                        reads = sample_read(genome, n_passes, read_length)
                    except Exception as e:
                        print(f"Error on {genome_id}: {e}")
                    for read in reads:
                        x[i] = read
                        y[i] = index
                        i += 1
                        progress_bar.update(1)
    np.save(f"{dst}x.npy", x)
    np.save(f"{dst}y.npy", y)
    with open(f"{dst}map.json", "w") as f:
        json.dump(index_to_taxonomic_label, f, indent=4)
    return i
